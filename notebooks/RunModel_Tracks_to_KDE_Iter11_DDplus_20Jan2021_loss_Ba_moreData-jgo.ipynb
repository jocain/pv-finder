{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in note\"book, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second attempt to read in track information and use it to predict the KDE used as input to PvFinder. This time, we are reading in poca KDEs rather than the original KDEs. \n",
    "\n",
    "collectdata_kde_C.py uses poca_z, poca_x, poca_y, major_axis_x, major_axis_y, and major_axis_z as the six track parameters (for the moment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  8 10:47:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:18:00.0 Off |                  N/A |\n",
      "| 34%   54C    P2    77W / 250W |  10896MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 29%   34C    P8    20W / 250W |   2910MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 3090    On   | 00000000:AF:00.0 Off |                  N/A |\n",
      "|  0%   35C    P8    30W / 350W |    554MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     10474      C   ...s/june2020-gpu/bin/python     2907MiB |\n",
      "|    0   N/A  N/A    104394      C   python                           4159MiB |\n",
      "|    0   N/A  N/A    271611      C   ...s/june2020-gpu/bin/python     3827MiB |\n",
      "|    1   N/A  N/A    239179      C   ...s/june2020-gpu/bin/python     2907MiB |\n",
      "|    2   N/A  N/A    231905      C   ...s/june2020-gpu/bin/python      551MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is first attempt to read in track information and use it to predict the KDE used as input to PvFinder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "##from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "# Name is the output file name\n",
    "\n",
    "\n",
    "##  201027 -- about to go to bed, so try 2500 epochs with lr = 1e55\n",
    "##  previous iteration had l4 = 3e-5 and cost dropped almost linearly\n",
    "##  for 100 epochs -- final training costs ~ 2.02, validation cost ~ 2.01\n",
    "\n",
    "## for iter 4, try 10 epochs with lr = 3e-6\n",
    "## usually have a big jump down at epoch 0; want to try a\n",
    "## small number of epochs per iteration and see what happens (iter4: 10 epochs gave\n",
    "## traiing cost dropping from 1.54 to 1.50 immediately, then dropping very slowly)\n",
    "folder = '20Jan_DDplus_loss_Ba_iter11_floatAll_10epochs_1em5_4xwill'\n",
    "name   = folder\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = 'jgo_files/' + folder\n",
    "output = Path(folder)\n",
    "\n",
    "\n",
    "# Size of batches\n",
    "batch_size = 48 ## batch_size = 24 ---> 4763MiB / 12066MiB on Titan V\n",
    "# How fast to learn\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From model/collectdata.py\n",
    "##from model.collectdata_kde_B import collect_t2kde_data\n",
    "## collectdata_kde_C should use the new poca KDE rather than the original kernel KDE\n",
    "from model.collectdata_kde_Ellipsoids import collect_t2kde_data\n",
    "\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "## kde_loss_D includes botha ratio term and a chisq term, 98% ave_chisq\n",
    "## kde_loss_E adds a chi^4 term to the kde_loss_D return value\n",
    "## this is intended to emphasize the importance of values significantly different than zero\n",
    "from model.kde_loss_Ba import Loss\n",
    "\n",
    "##  TracksToKDE_Ellipsoids_SevenLayerCake has 7 hidden layers producing the 4000-bin KDE historgram\n",
    "##  It takes 9 input features (pocca centers + (A,B,C,D,E,F) . \n",
    "from model.models_kde import TracksToKDE_Ellipsoids_DDplus as Model\n",
    "\n",
    "\n",
    "from model.training_kde import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(2)\n",
    "##device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "##if torch.cuda.device_count() > 1:\n",
    "##    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct, child =  0    Linear(in_features=9, out_features=50, bias=True)\n",
      "ct, child =  1    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  2    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  3    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  4    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  5    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  6    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  7    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  8    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  9    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  10    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  11    Linear(in_features=50, out_features=16000, bias=True)\n",
      "ct, child =  12    Conv1d(4, 25, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  13    Conv1d(25, 1, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "ct, child =  14    Linear(in_features=4000, out_features=4000, bias=True)\n",
      "ct, child =  15    Conv1d(25, 1, kernel_size=(15,), stride=(1,), padding=(7,))\n",
      "ct, child =  16    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  17    Dropout(p=0.15, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "## a comment on the web at https://pytorch.org/docs/stable/optim.html says\n",
    "\"\"\"\n",
    "If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. \n",
    "Parameters of a model after .cuda() will be different objects with those before the call.\n",
    "\n",
    "In general, you should make sure that optimized parameters live in consistent locations when \n",
    "optimizers are constructed and used.\n",
    "\"\"\"\n",
    "## so move this here (although we are using model.to(device) not explicitly using .cuda()\n",
    "\n",
    "nOut1 = 50\n",
    "nOut2 = 50\n",
    "nOut3 = 50\n",
    "nOut4 = 50\n",
    "nOut5 = 50\n",
    "nOut6 = 50\n",
    "nOut7 = 50\n",
    "nOut8 = 50\n",
    "nOut9 = 50\n",
    "nOut10 = 50\n",
    "nOut11 = 50\n",
    "latentChannels = 4\n",
    "model = Model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11,latentChannels)\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "  print('ct, child = ',ct, \"  \", child)\n",
    "  if ct < 0:\n",
    "    print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False \n",
    "  ct += 1\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "##  loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "##loss = Loss(epsilon=3e-5, debug=False)\n",
    "loss = Loss(epsilon=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "##optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  jgo_files/20Jan_DDplus_loss_Ba_iter11_floatAll_10epochs_1em5_4xwill\n",
      "for model_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12new.weight\n",
      "index, k =   23    layer12new.bias\n",
      "index, k =   24    conv1.weight\n",
      "index, k =   25    conv1.bias\n",
      "index, k =   26    conv2.weight\n",
      "index, k =   27    conv2.bias\n",
      "index, k =   28    fc1.weight\n",
      "index, k =   29    fc1.bias\n",
      "index, k =   30    finalFilter.weight\n",
      "index, k =   31    finalFilter.bias\n",
      "dict_name =  ML/20Jan_DDplus_loss_Ba_iter10_floatAll_75epochs_1em5_4xwill/20Jan_DDplus_loss_Ba_iter10_floatAll_75epochs_1em5_4xwill_30.pyt\n",
      " \n",
      "  for pretrained_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12new.weight\n",
      "index, k =   23    layer12new.bias\n",
      "index, k =   24    conv1.weight\n",
      "index, k =   25    conv1.bias\n",
      "index, k =   26    conv2.weight\n",
      "index, k =   27    conv2.bias\n",
      "index, k =   28    fc1.weight\n",
      "index, k =   29    fc1.bias\n",
      "index, k =   30    finalFilter.weight\n",
      "index, k =   31    finalFilter.bias\n",
      "pretrained_dict iterated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('output = ',output)\n",
    "##print('oldOutput = ',oldOutput)\n",
    "##  use the first four layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "model_dict = model.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_dict\")\n",
    "index = 0\n",
    "for k,v in model_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "##    print(\"value = \", v)\n",
    " \n",
    "updated_dict = model_dict\n",
    "##print(\"updated_dict = \",updated_dict)\n",
    "## when starting \"ab initio\", reduce biases as the bias gets summed for each track\n",
    "## contributing to the predicted KDE\n",
    "updated_dict[\"layer1.bias\"] = 0.005*model_dict[\"layer1.bias\"]\n",
    "updated_dict[\"layer2.bias\"] = 0.005*model_dict[\"layer2.bias\"]\n",
    "updated_dict[\"layer3.bias\"] = 0.005*model_dict[\"layer3.bias\"]\n",
    "updated_dict[\"layer4.bias\"] = 0.005*model_dict[\"layer4.bias\"]\n",
    "updated_dict[\"layer5.bias\"] = 0.005*model_dict[\"layer5.bias\"]\n",
    "updated_dict[\"layer6.bias\"] = 0.005*model_dict[\"layer6.bias\"]\n",
    "updated_dict[\"layer7.bias\"] = 0.005*model_dict[\"layer7.bias\"]\n",
    "updated_dict[\"layer8.bias\"] = 0.005*model_dict[\"layer8.bias\"]\n",
    "updated_dict[\"layer9.bias\"] = 0.005*model_dict[\"layer9.bias\"]\n",
    "updated_dict[\"layer10.bias\"] = 0.005*model_dict[\"layer10.bias\"]\n",
    "updated_dict[\"layer11.bias\"] = 0.005*model_dict[\"layer11.bias\"]\n",
    "\n",
    "model.load_state_dict(updated_dict,strict=False)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "##print(\"updated model_dict = \",model_dict)\n",
    "\n",
    "## print(\" \\n\",\"  for pretrained_dict\")\n",
    "## index = 0\n",
    "##for k,v in pretrained_dict.items():\n",
    "##    print(\"index, k =  \",index,\"  \",k)\n",
    "##    index = index+1\n",
    "## mds  \n",
    "\n",
    "##pretrained_dict = torch.load('ML/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50_final.pyt')\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "##pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "##print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "##model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "##model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n",
    "## print('model_dict =    ', model_dict)\n",
    "\n",
    "## finished at training cost = 1.46, validation cost = 1.50\n",
    "##d_folder = '25December__DDplus_loss_Ba_iter7_floatAll_800epochs_4em6'\n",
    "d_folder = '20Jan_DDplus_loss_Ba_iter10_floatAll_75epochs_1em5_4xwill'\n",
    "d_name = d_folder\n",
    "suffix = '30'\n",
    "dict_name = 'ML/' + d_folder + '/' + d_name + '_'+ suffix + '.pyt'\n",
    "print('dict_name = ',dict_name)\n",
    "pretrained_dict = torch.load(dict_name)\n",
    "\n",
    "print(\" \")\n",
    "print(\"  for pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    " \n",
    "\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "pocaMx.shape =  (80000,)\n",
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  199\n",
      "len(pocaMx[1]) =  25\n",
      "len(pocaMx[2]) =  369\n",
      "len(pocaMx[3]) =  143\n",
      "len(pocaMx[4]) =  160\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 199\n",
      " iEvt, nTrks =  1 25\n",
      " iEvt, nTrks =  2 369\n",
      " iEvt, nTrks =  3 143\n",
      " iEvt, nTrks =  4 160\n",
      " iEvt, nTrks =  5 260\n",
      " iEvt, nTrks =  6 237\n",
      " iEvt, nTrks =  7 327\n",
      " iEvt, nTrks =  8 178\n",
      " iEvt, nTrks =  9 106\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  0.00045611936\n",
      "majorAxis[iTrk][1][0] =  -4.8292455e-05\n",
      "majorAxis[iTrk][2][0] =  0.090019904\n",
      "minorAxis_1[iTrk][0][0] =  -1.8602173\n",
      "minorAxis_1[iTrk][1][0] =  -17.569641\n",
      "minorAxis_1[iTrk][2][0] =  4.7891795e-08\n",
      "minorAxis_2[iTrk][0][0] =  -17.569414\n",
      "minorAxis_2[iTrk][1][0] =  1.8601931\n",
      "minorAxis_2[iTrk][2][0] =  0.0900199\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.002360258\n",
      "majorAxis[iTrk][1][0] =  -0.007426616\n",
      "majorAxis[iTrk][2][0] =  0.3710108\n",
      "minorAxis_1[iTrk][0][0] =  -16.837948\n",
      "minorAxis_1[iTrk][1][0] =  -5.3512807\n",
      "minorAxis_1[iTrk][2][0] =  8.157131e-09\n",
      "minorAxis_2[iTrk][0][0] =  -5.3501005\n",
      "minorAxis_2[iTrk][1][0] =  16.834236\n",
      "minorAxis_2[iTrk][2][0] =  0.3710108\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  6.220712e-05\n",
      "majorAxis[iTrk][1][0] =  -4.4594188e-05\n",
      "majorAxis[iTrk][2][0] =  0.036773544\n",
      "minorAxis_1[iTrk][0][0] =  10.293747\n",
      "minorAxis_1[iTrk][1][0] =  14.359369\n",
      "minorAxis_1[iTrk][2][0] =  1.571041e-06\n",
      "minorAxis_2[iTrk][0][0] =  14.359338\n",
      "minorAxis_2[iTrk][1][0] =  -10.293725\n",
      "minorAxis_2[iTrk][2][0] =  -0.03677354\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0033452737\n",
      "majorAxis[iTrk][1][0] =  0.00013028442\n",
      "majorAxis[iTrk][2][0] =  0.2431933\n",
      "minorAxis_1[iTrk][0][0] =  0.6875674\n",
      "minorAxis_1[iTrk][1][0] =  -17.65446\n",
      "minorAxis_1[iTrk][2][0] =  -6.6602626e-09\n",
      "minorAxis_2[iTrk][0][0] =  -17.652788\n",
      "minorAxis_2[iTrk][1][0] =  -0.68750226\n",
      "minorAxis_2[iTrk][2][0] =  0.2431933\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00068196515\n",
      "majorAxis[iTrk][1][0] =  -0.00044562915\n",
      "majorAxis[iTrk][2][0] =  0.119970225\n",
      "minorAxis_1[iTrk][0][0] =  9.664597\n",
      "minorAxis_1[iTrk][1][0] =  -14.790141\n",
      "minorAxis_1[iTrk][2][0] =  1.9819232e-08\n",
      "minorAxis_2[iTrk][0][0] =  -14.789802\n",
      "minorAxis_2[iTrk][1][0] =  -9.664374\n",
      "minorAxis_2[iTrk][2][0] =  -0.11997023\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -8.245073e-05\n",
      "majorAxis[iTrk][1][0] =  0.00015860004\n",
      "majorAxis[iTrk][2][0] =  0.05619731\n",
      "minorAxis_1[iTrk][0][0] =  -15.676071\n",
      "minorAxis_1[iTrk][1][0] =  -8.149452\n",
      "minorAxis_1[iTrk][2][0] =  4.1105773e-07\n",
      "minorAxis_2[iTrk][0][0] =  -8.14941\n",
      "minorAxis_2[iTrk][1][0] =  15.675991\n",
      "minorAxis_2[iTrk][2][0] =  -0.056197315\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00015151131\n",
      "majorAxis[iTrk][1][0] =  0.00067339616\n",
      "majorAxis[iTrk][2][0] =  0.11042937\n",
      "minorAxis_1[iTrk][0][0] =  17.236937\n",
      "minorAxis_1[iTrk][1][0] =  3.8782384\n",
      "minorAxis_1[iTrk][2][0] =  2.3217373e-08\n",
      "minorAxis_2[iTrk][0][0] =  3.8781626\n",
      "minorAxis_2[iTrk][1][0] =  -17.236599\n",
      "minorAxis_2[iTrk][2][0] =  0.11042936\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -7.577422e-05\n",
      "majorAxis[iTrk][1][0] =  -0.00036802414\n",
      "majorAxis[iTrk][2][0] =  0.08147708\n",
      "minorAxis_1[iTrk][0][0] =  -17.304853\n",
      "minorAxis_1[iTrk][1][0] =  3.5629773\n",
      "minorAxis_1[iTrk][2][0] =  5.80501e-09\n",
      "minorAxis_2[iTrk][0][0] =  3.5629392\n",
      "minorAxis_2[iTrk][1][0] =  17.304668\n",
      "minorAxis_2[iTrk][2][0] =  0.081477076\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00013397264\n",
      "majorAxis[iTrk][1][0] =  0.00094400026\n",
      "majorAxis[iTrk][2][0] =  0.12978876\n",
      "minorAxis_1[iTrk][0][0] =  17.492561\n",
      "minorAxis_1[iTrk][1][0] =  -2.4825466\n",
      "minorAxis_1[iTrk][2][0] =  1.1329301e-08\n",
      "minorAxis_2[iTrk][0][0] =  -2.4824798\n",
      "minorAxis_2[iTrk][1][0] =  -17.492088\n",
      "minorAxis_2[iTrk][2][0] =  0.12978874\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00043501743\n",
      "majorAxis[iTrk][1][0] =  -0.0016521378\n",
      "majorAxis[iTrk][2][0] =  0.17373301\n",
      "minorAxis_1[iTrk][0][0] =  -17.0855\n",
      "minorAxis_1[iTrk][1][0] =  -4.4987106\n",
      "minorAxis_1[iTrk][2][0] =  -7.7275175e-08\n",
      "minorAxis_2[iTrk][0][0] =  -4.4984937\n",
      "minorAxis_2[iTrk][1][0] =  17.084677\n",
      "minorAxis_2[iTrk][2][0] =  0.17373303\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  1\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_1.h5 in 127.3 s\n",
      "pocaMx.shape =  (80000,)\n",
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  222\n",
      "len(pocaMx[1]) =  133\n",
      "len(pocaMx[2]) =  259\n",
      "len(pocaMx[3]) =  114\n",
      "len(pocaMx[4]) =  143\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 222\n",
      " iEvt, nTrks =  1 133\n",
      " iEvt, nTrks =  2 259\n",
      " iEvt, nTrks =  3 114\n",
      " iEvt, nTrks =  4 143\n",
      " iEvt, nTrks =  5 136\n",
      " iEvt, nTrks =  6 397\n",
      " iEvt, nTrks =  7 370\n",
      " iEvt, nTrks =  8 97\n",
      " iEvt, nTrks =  9 67\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  -0.001036478\n",
      "majorAxis[iTrk][1][0] =  0.0009833863\n",
      "majorAxis[iTrk][2][0] =  0.15887721\n",
      "minorAxis_1[iTrk][0][0] =  -12.160475\n",
      "minorAxis_1[iTrk][1][0] =  -12.817002\n",
      "minorAxis_1[iTrk][2][0] =  0.0\n",
      "minorAxis_2[iTrk][0][0] =  -12.816484\n",
      "minorAxis_2[iTrk][1][0] =  12.159985\n",
      "minorAxis_2[iTrk][2][0] =  -0.15887721\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0016579849\n",
      "majorAxis[iTrk][1][0] =  0.0020989499\n",
      "majorAxis[iTrk][2][0] =  0.21738033\n",
      "minorAxis_1[iTrk][0][0] =  -13.864233\n",
      "minorAxis_1[iTrk][1][0] =  10.95152\n",
      "minorAxis_1[iTrk][2][0] =  -3.3017489e-09\n",
      "minorAxis_2[iTrk][0][0] =  10.95069\n",
      "minorAxis_2[iTrk][1][0] =  13.863184\n",
      "minorAxis_2[iTrk][2][0] =  -0.21738033\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00012481198\n",
      "majorAxis[iTrk][1][0] =  -0.00028747538\n",
      "majorAxis[iTrk][2][0] =  0.07441149\n",
      "minorAxis_1[iTrk][0][0] =  -16.206305\n",
      "minorAxis_1[iTrk][1][0] =  -7.036224\n",
      "minorAxis_1[iTrk][2][0] =  5.3456716e-08\n",
      "minorAxis_2[iTrk][0][0] =  -7.0361605\n",
      "minorAxis_2[iTrk][1][0] =  16.20616\n",
      "minorAxis_2[iTrk][2][0] =  0.07441148\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.007920195\n",
      "majorAxis[iTrk][1][0] =  -0.009694931\n",
      "majorAxis[iTrk][2][0] =  0.47021532\n",
      "minorAxis_1[iTrk][0][0] =  -13.682467\n",
      "minorAxis_1[iTrk][1][0] =  11.177781\n",
      "minorAxis_1[iTrk][2][0] =  1.8638048e-10\n",
      "minorAxis_2[iTrk][0][0] =  11.173822\n",
      "minorAxis_2[iTrk][1][0] =  13.677622\n",
      "minorAxis_2[iTrk][2][0] =  0.47021535\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00038854493\n",
      "majorAxis[iTrk][1][0] =  0.0009230774\n",
      "majorAxis[iTrk][2][0] =  0.13301943\n",
      "minorAxis_1[iTrk][0][0] =  -16.284061\n",
      "minorAxis_1[iTrk][1][0] =  6.854344\n",
      "minorAxis_1[iTrk][2][0] =  2.2469074e-07\n",
      "minorAxis_2[iTrk][0][0] =  6.8541493\n",
      "minorAxis_2[iTrk][1][0] =  16.283602\n",
      "minorAxis_2[iTrk][2][0] =  -0.13301945\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -5.6093595e-05\n",
      "majorAxis[iTrk][1][0] =  0.000114469876\n",
      "majorAxis[iTrk][2][0] =  0.04745733\n",
      "minorAxis_1[iTrk][0][0] =  15.865369\n",
      "minorAxis_1[iTrk][1][0] =  7.774496\n",
      "minorAxis_1[iTrk][2][0] =  1.8465234e-06\n",
      "minorAxis_2[iTrk][0][0] =  7.774468\n",
      "minorAxis_2[iTrk][1][0] =  -15.865313\n",
      "minorAxis_2[iTrk][2][0] =  0.04745733\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  9.375396e-05\n",
      "majorAxis[iTrk][1][0] =  0.0002926058\n",
      "majorAxis[iTrk][2][0] =  0.07367872\n",
      "minorAxis_1[iTrk][0][0] =  -16.825275\n",
      "minorAxis_1[iTrk][1][0] =  5.390994\n",
      "minorAxis_1[iTrk][2][0] =  -2.1861728e-08\n",
      "minorAxis_2[iTrk][0][0] =  5.3909473\n",
      "minorAxis_2[iTrk][1][0] =  16.825129\n",
      "minorAxis_2[iTrk][2][0] =  -0.07367872\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -1.1543522e-06\n",
      "majorAxis[iTrk][1][0] =  2.8112001e-05\n",
      "majorAxis[iTrk][2][0] =  0.022295665\n",
      "minorAxis_1[iTrk][0][0] =  -17.652967\n",
      "minorAxis_1[iTrk][1][0] =  -0.7248769\n",
      "minorAxis_1[iTrk][2][0] =  1.7815448e-07\n",
      "minorAxis_2[iTrk][0][0] =  -0.7248763\n",
      "minorAxis_2[iTrk][1][0] =  17.652954\n",
      "minorAxis_2[iTrk][2][0] =  -0.022295661\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.2612214\n",
      "majorAxis[iTrk][1][0] =  0.83076316\n",
      "majorAxis[iTrk][2][0] =  3.8745012\n",
      "minorAxis_1[iTrk][0][0] =  -16.85429\n",
      "minorAxis_1[iTrk][1][0] =  -5.299587\n",
      "minorAxis_1[iTrk][2][0] =  2.0865195e-11\n",
      "minorAxis_2[iTrk][0][0] =  -5.1705856\n",
      "minorAxis_2[iTrk][1][0] =  16.444027\n",
      "minorAxis_2[iTrk][2][0] =  -3.874501\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.057592034\n",
      "majorAxis[iTrk][1][0] =  0.06503555\n",
      "majorAxis[iTrk][2][0] =  1.2373537\n",
      "minorAxis_1[iTrk][0][0] =  13.227038\n",
      "minorAxis_1[iTrk][1][0] =  11.713163\n",
      "minorAxis_1[iTrk][2][0] =  1.7679876e-10\n",
      "minorAxis_2[iTrk][0][0] =  11.684402\n",
      "minorAxis_2[iTrk][1][0] =  -13.194561\n",
      "minorAxis_2[iTrk][2][0] =  1.2373537\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  2\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_2.h5 in 128.0 s\n",
      "pocaMx.shape =  (80000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  196\n",
      "len(pocaMx[1]) =  35\n",
      "len(pocaMx[2]) =  265\n",
      "len(pocaMx[3]) =  128\n",
      "len(pocaMx[4]) =  124\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 196\n",
      " iEvt, nTrks =  1 35\n",
      " iEvt, nTrks =  2 265\n",
      " iEvt, nTrks =  3 128\n",
      " iEvt, nTrks =  4 124\n",
      " iEvt, nTrks =  5 122\n",
      " iEvt, nTrks =  6 300\n",
      " iEvt, nTrks =  7 179\n",
      " iEvt, nTrks =  8 243\n",
      " iEvt, nTrks =  9 112\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  -2.440992e-05\n",
      "majorAxis[iTrk][1][0] =  -0.00038087237\n",
      "majorAxis[iTrk][2][0] =  0.08211532\n",
      "minorAxis_1[iTrk][0][0] =  -17.631672\n",
      "minorAxis_1[iTrk][1][0] =  1.130005\n",
      "minorAxis_1[iTrk][2][0] =  4.7444193e-08\n",
      "minorAxis_2[iTrk][0][0] =  1.1299927\n",
      "minorAxis_2[iTrk][1][0] =  17.631481\n",
      "minorAxis_2[iTrk][2][0] =  0.08211532\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.02277395\n",
      "majorAxis[iTrk][1][0] =  0.0014473597\n",
      "majorAxis[iTrk][2][0] =  0.6347583\n",
      "minorAxis_1[iTrk][0][0] =  -1.1205891\n",
      "minorAxis_1[iTrk][1][0] =  -17.632273\n",
      "minorAxis_1[iTrk][2][0] =  2.1543272e-09\n",
      "minorAxis_2[iTrk][0][0] =  -17.620888\n",
      "minorAxis_2[iTrk][1][0] =  1.1198657\n",
      "minorAxis_2[iTrk][2][0] =  -0.63475823\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0004024825\n",
      "majorAxis[iTrk][1][0] =  -0.00023784715\n",
      "majorAxis[iTrk][2][0] =  0.090883136\n",
      "minorAxis_1[iTrk][0][0] =  -8.988615\n",
      "minorAxis_1[iTrk][1][0] =  -15.210441\n",
      "minorAxis_1[iTrk][2][0] =  -6.56547e-08\n",
      "minorAxis_2[iTrk][0][0] =  -15.21024\n",
      "minorAxis_2[iTrk][1][0] =  8.988497\n",
      "minorAxis_2[iTrk][2][0] =  0.090883136\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0068744724\n",
      "majorAxis[iTrk][1][0] =  0.0017050834\n",
      "majorAxis[iTrk][2][0] =  0.3537121\n",
      "minorAxis_1[iTrk][0][0] =  4.2532983\n",
      "minorAxis_1[iTrk][1][0] =  -17.148241\n",
      "minorAxis_1[iTrk][2][0] =  1.1939819e-09\n",
      "minorAxis_2[iTrk][0][0] =  -17.144806\n",
      "minorAxis_2[iTrk][1][0] =  -4.252446\n",
      "minorAxis_2[iTrk][2][0] =  0.3537121\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.004920899\n",
      "majorAxis[iTrk][1][0] =  0.0009170567\n",
      "majorAxis[iTrk][2][0] =  0.2973651\n",
      "minorAxis_1[iTrk][0][0] =  -3.236844\n",
      "minorAxis_1[iTrk][1][0] =  -17.36881\n",
      "minorAxis_1[iTrk][2][0] =  -4.7397712e-09\n",
      "minorAxis_2[iTrk][0][0] =  -17.36635\n",
      "minorAxis_2[iTrk][1][0] =  3.2363856\n",
      "minorAxis_2[iTrk][2][0] =  -0.29736507\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.0001240533\n",
      "majorAxis[iTrk][1][0] =  0.00033394952\n",
      "majorAxis[iTrk][2][0] =  0.079335004\n",
      "minorAxis_1[iTrk][0][0] =  -16.562042\n",
      "minorAxis_1[iTrk][1][0] =  -6.1523557\n",
      "minorAxis_1[iTrk][2][0] =  3.1261713e-08\n",
      "minorAxis_2[iTrk][0][0] =  -6.1522937\n",
      "minorAxis_2[iTrk][1][0] =  16.561876\n",
      "minorAxis_2[iTrk][2][0] =  -0.079335004\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00010132754\n",
      "majorAxis[iTrk][1][0] =  6.684385e-05\n",
      "majorAxis[iTrk][2][0] =  0.046310693\n",
      "minorAxis_1[iTrk][0][0] =  -9.728917\n",
      "minorAxis_1[iTrk][1][0] =  14.747911\n",
      "minorAxis_1[iTrk][2][0] =  -2.3591362e-07\n",
      "minorAxis_2[iTrk][0][0] =  14.74786\n",
      "minorAxis_2[iTrk][1][0] =  9.728883\n",
      "minorAxis_2[iTrk][2][0] =  -0.04631069\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0042806785\n",
      "majorAxis[iTrk][1][0] =  0.004939851\n",
      "majorAxis[iTrk][2][0] =  0.3398017\n",
      "minorAxis_1[iTrk][0][0] =  13.3521\n",
      "minorAxis_1[iTrk][1][0] =  -11.5704\n",
      "minorAxis_1[iTrk][2][0] =  1.21654296e-08\n",
      "minorAxis_2[iTrk][0][0] =  -11.56826\n",
      "minorAxis_2[iTrk][1][0] =  -13.349631\n",
      "minorAxis_2[iTrk][2][0] =  0.33980173\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00013103899\n",
      "majorAxis[iTrk][1][0] =  -0.0006021903\n",
      "majorAxis[iTrk][2][0] =  0.10434653\n",
      "minorAxis_1[iTrk][0][0] =  -17.26384\n",
      "minorAxis_1[iTrk][1][0] =  3.7566798\n",
      "minorAxis_1[iTrk][2][0] =  -9.616703e-08\n",
      "minorAxis_2[iTrk][0][0] =  3.7566135\n",
      "minorAxis_2[iTrk][1][0] =  17.263535\n",
      "minorAxis_2[iTrk][2][0] =  0.10434652\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0016481678\n",
      "majorAxis[iTrk][1][0] =  -0.0019788505\n",
      "majorAxis[iTrk][2][0] =  0.21330062\n",
      "minorAxis_1[iTrk][0][0] =  -13.575765\n",
      "minorAxis_1[iTrk][1][0] =  -11.307139\n",
      "minorAxis_1[iTrk][2][0] =  8.543098e-09\n",
      "minorAxis_2[iTrk][0][0] =  -11.306314\n",
      "minorAxis_2[iTrk][1][0] =  13.574774\n",
      "minorAxis_2[iTrk][2][0] =  0.21330062\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  3\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_3.h5 in 130.1 s\n",
      "pocaMx.shape =  (80000,)\n",
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  204\n",
      "len(pocaMx[1]) =  33\n",
      "len(pocaMx[2]) =  206\n",
      "len(pocaMx[3]) =  150\n",
      "len(pocaMx[4]) =  96\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 204\n",
      " iEvt, nTrks =  1 33\n",
      " iEvt, nTrks =  2 206\n",
      " iEvt, nTrks =  3 150\n",
      " iEvt, nTrks =  4 96\n",
      " iEvt, nTrks =  5 10\n",
      " iEvt, nTrks =  6 174\n",
      " iEvt, nTrks =  7 320\n",
      " iEvt, nTrks =  8 164\n",
      " iEvt, nTrks =  9 119\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  0.00057876867\n",
      "majorAxis[iTrk][1][0] =  0.00037603904\n",
      "majorAxis[iTrk][2][0] =  0.110427074\n",
      "minorAxis_1[iTrk][0][0] =  9.62588\n",
      "minorAxis_1[iTrk][1][0] =  -14.81537\n",
      "minorAxis_1[iTrk][2][0] =  8.391163e-09\n",
      "minorAxis_2[iTrk][0][0] =  -14.815081\n",
      "minorAxis_2[iTrk][1][0] =  -9.625692\n",
      "minorAxis_2[iTrk][2][0] =  0.11042709\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -7.687664e-05\n",
      "majorAxis[iTrk][1][0] =  -0.0017985329\n",
      "majorAxis[iTrk][2][0] =  0.17833562\n",
      "minorAxis_1[iTrk][0][0] =  -17.651728\n",
      "minorAxis_1[iTrk][1][0] =  0.7545069\n",
      "minorAxis_1[iTrk][2][0] =  -7.932265e-09\n",
      "minorAxis_2[iTrk][0][0] =  0.75446844\n",
      "minorAxis_2[iTrk][1][0] =  17.650827\n",
      "minorAxis_2[iTrk][2][0] =  0.17833562\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  4.5855802e-05\n",
      "majorAxis[iTrk][1][0] =  -0.00054240844\n",
      "majorAxis[iTrk][2][0] =  0.098067455\n",
      "minorAxis_1[iTrk][0][0] =  17.605043\n",
      "minorAxis_1[iTrk][1][0] =  1.4883496\n",
      "minorAxis_1[iTrk][2][0] =  -2.7847218e-08\n",
      "minorAxis_2[iTrk][0][0] =  1.4883265\n",
      "minorAxis_2[iTrk][1][0] =  -17.604773\n",
      "minorAxis_2[iTrk][2][0] =  -0.098067455\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.0013144773\n",
      "majorAxis[iTrk][1][0] =  0.0008680699\n",
      "majorAxis[iTrk][2][0] =  0.16682307\n",
      "minorAxis_1[iTrk][0][0] =  -9.736217\n",
      "minorAxis_1[iTrk][1][0] =  -14.743094\n",
      "minorAxis_1[iTrk][2][0] =  -1.7552136e-08\n",
      "minorAxis_2[iTrk][0][0] =  -14.742435\n",
      "minorAxis_2[iTrk][1][0] =  9.735782\n",
      "minorAxis_2[iTrk][2][0] =  -0.16682304\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.032227762\n",
      "majorAxis[iTrk][1][0] =  0.007741693\n",
      "majorAxis[iTrk][2][0] =  0.76488173\n",
      "minorAxis_1[iTrk][0][0] =  -4.1267405\n",
      "minorAxis_1[iTrk][1][0] =  17.179138\n",
      "minorAxis_1[iTrk][2][0] =  -2.3529467e-10\n",
      "minorAxis_2[iTrk][0][0] =  17.16303\n",
      "minorAxis_2[iTrk][1][0] =  4.122871\n",
      "minorAxis_2[iTrk][2][0] =  -0.7648817\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  1.9753945\n",
      "majorAxis[iTrk][1][0] =  2.5669005\n",
      "majorAxis[iTrk][2][0] =  7.226382\n",
      "minorAxis_1[iTrk][0][0] =  14.0017\n",
      "minorAxis_1[iTrk][1][0] =  -10.7752075\n",
      "minorAxis_1[iTrk][2][0] =  5.3286344e-11\n",
      "minorAxis_2[iTrk][0][0] =  -9.832683\n",
      "minorAxis_2[iTrk][1][0] =  -12.776951\n",
      "minorAxis_2[iTrk][2][0] =  7.226381\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.0026900356\n",
      "majorAxis[iTrk][1][0] =  -0.0015841618\n",
      "majorAxis[iTrk][2][0] =  0.234843\n",
      "minorAxis_1[iTrk][0][0] =  -8.965469\n",
      "minorAxis_1[iTrk][1][0] =  15.224096\n",
      "minorAxis_1[iTrk][2][0] =  2.8236277e-08\n",
      "minorAxis_2[iTrk][0][0] =  15.222751\n",
      "minorAxis_2[iTrk][1][0] =  8.964677\n",
      "minorAxis_2[iTrk][2][0] =  0.234843\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.0001692281\n",
      "majorAxis[iTrk][1][0] =  0.0003505444\n",
      "majorAxis[iTrk][2][0] =  0.08292902\n",
      "minorAxis_1[iTrk][0][0] =  -15.910811\n",
      "minorAxis_1[iTrk][1][0] =  -7.68107\n",
      "minorAxis_1[iTrk][2][0] =  1.587002e-08\n",
      "minorAxis_2[iTrk][0][0] =  -7.680986\n",
      "minorAxis_2[iTrk][1][0] =  15.910635\n",
      "minorAxis_2[iTrk][2][0] =  -0.08292903\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0017714669\n",
      "majorAxis[iTrk][1][0] =  -0.001515166\n",
      "majorAxis[iTrk][2][0] =  0.20293355\n",
      "minorAxis_1[iTrk][0][0] =  11.483943\n",
      "minorAxis_1[iTrk][1][0] =  13.426532\n",
      "minorAxis_1[iTrk][2][0] =  -2.7840934e-09\n",
      "minorAxis_2[iTrk][0][0] =  13.425648\n",
      "minorAxis_2[iTrk][1][0] =  -11.483187\n",
      "minorAxis_2[iTrk][2][0] =  -0.20293356\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0006359923\n",
      "majorAxis[iTrk][1][0] =  -0.0003371759\n",
      "majorAxis[iTrk][2][0] =  0.112773284\n",
      "minorAxis_1[iTrk][0][0] =  8.275655\n",
      "minorAxis_1[iTrk][1][0] =  15.609813\n",
      "minorAxis_1[iTrk][2][0] =  -5.6373224e-08\n",
      "minorAxis_2[iTrk][0][0] =  15.609494\n",
      "minorAxis_2[iTrk][1][0] =  -8.275486\n",
      "minorAxis_2[iTrk][2][0] =  -0.11277328\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  4\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_4.h5 in 131.4 s\n",
      "outer loop X.shape =  (320000, 9, 600)\n",
      "Constructing 320000 event dataset took 1.702 s\n",
      "x_t.shape =  torch.Size([320000, 9, 600])\n",
      "x_t.shape[0] =  320000\n",
      "x_t.shape[1] =  9\n",
      "x_t.shape =  torch.Size([320000, 9, 600])\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pocaMx.shape =  (20000,)\n",
      "nEvts =  20000\n",
      "len(pocaMx[0]) =  211\n",
      "len(pocaMx[1]) =  21\n",
      "len(pocaMx[2]) =  20\n",
      "len(pocaMx[3]) =  198\n",
      "len(pocaMx[4]) =  233\n",
      "majorAxis.shape =  (20000, 3)\n",
      "minorAxis_1.shape =  (20000, 3)\n",
      "minorAxis_2.shape =  (20000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  20000\n",
      " iEvt, nTrks =  0 211\n",
      " iEvt, nTrks =  1 21\n",
      " iEvt, nTrks =  2 20\n",
      " iEvt, nTrks =  3 198\n",
      " iEvt, nTrks =  4 233\n",
      " iEvt, nTrks =  5 85\n",
      " iEvt, nTrks =  6 223\n",
      " iEvt, nTrks =  7 425\n",
      " iEvt, nTrks =  8 252\n",
      " iEvt, nTrks =  9 169\n",
      "A.shape =  (20000,)\n",
      "majorAxis[iTrk][0][0] =  -0.00023452607\n",
      "majorAxis[iTrk][1][0] =  -0.00047206535\n",
      "majorAxis[iTrk][2][0] =  0.096502915\n",
      "minorAxis_1[iTrk][0][0] =  -15.822749\n",
      "minorAxis_1[iTrk][1][0] =  7.8608756\n",
      "minorAxis_1[iTrk][2][0] =  -2.6228399e-08\n",
      "minorAxis_2[iTrk][0][0] =  7.860759\n",
      "minorAxis_2[iTrk][1][0] =  15.822513\n",
      "minorAxis_2[iTrk][2][0] =  0.096502915\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.37655562\n",
      "majorAxis[iTrk][1][0] =  0.2768704\n",
      "majorAxis[iTrk][2][0] =  2.8546858\n",
      "minorAxis_1[iTrk][0][0] =  -10.466048\n",
      "minorAxis_1[iTrk][1][0] =  -14.234274\n",
      "minorAxis_1[iTrk][2][0] =  2.2974699e-11\n",
      "minorAxis_2[iTrk][0][0] =  -14.04724\n",
      "minorAxis_2[iTrk][1][0] =  10.328527\n",
      "minorAxis_2[iTrk][2][0] =  -2.8546853\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.024279848\n",
      "majorAxis[iTrk][1][0] =  0.0019689242\n",
      "majorAxis[iTrk][2][0] =  0.65580803\n",
      "minorAxis_1[iTrk][0][0] =  -1.4280497\n",
      "minorAxis_1[iTrk][1][0] =  -17.610037\n",
      "minorAxis_1[iTrk][2][0] =  -6.123401e-10\n",
      "minorAxis_2[iTrk][0][0] =  -17.597902\n",
      "minorAxis_2[iTrk][1][0] =  1.4270656\n",
      "minorAxis_2[iTrk][2][0] =  -0.6558081\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.007825993\n",
      "majorAxis[iTrk][1][0] =  0.004052097\n",
      "majorAxis[iTrk][2][0] =  0.3945435\n",
      "minorAxis_1[iTrk][0][0] =  8.123606\n",
      "minorAxis_1[iTrk][1][0] =  15.689478\n",
      "minorAxis_1[iTrk][2][0] =  -2.4940747e-10\n",
      "minorAxis_2[iTrk][0][0] =  15.685566\n",
      "minorAxis_2[iTrk][1][0] =  -8.12158\n",
      "minorAxis_2[iTrk][2][0] =  0.3945435\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0046102717\n",
      "majorAxis[iTrk][1][0] =  -0.0016007021\n",
      "majorAxis[iTrk][2][0] =  0.29361814\n",
      "minorAxis_1[iTrk][0][0] =  -5.794979\n",
      "minorAxis_1[iTrk][1][0] =  -16.690445\n",
      "minorAxis_1[iTrk][2][0] =  2.4897104e-09\n",
      "minorAxis_2[iTrk][0][0] =  -16.688139\n",
      "minorAxis_2[iTrk][1][0] =  5.794179\n",
      "minorAxis_2[iTrk][2][0] =  0.2936181\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00020041714\n",
      "majorAxis[iTrk][1][0] =  0.00010468164\n",
      "majorAxis[iTrk][2][0] =  0.06320469\n",
      "minorAxis_1[iTrk][0][0] =  8.179679\n",
      "minorAxis_1[iTrk][1][0] =  15.660318\n",
      "minorAxis_1[iTrk][2][0] =  7.40176e-08\n",
      "minorAxis_2[iTrk][0][0] =  15.660218\n",
      "minorAxis_2[iTrk][1][0] =  -8.179626\n",
      "minorAxis_2[iTrk][2][0] =  0.06320469\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00020603223\n",
      "majorAxis[iTrk][1][0] =  -0.0005662605\n",
      "majorAxis[iTrk][2][0] =  0.10317981\n",
      "minorAxis_1[iTrk][0][0] =  -16.603\n",
      "minorAxis_1[iTrk][1][0] =  6.040953\n",
      "minorAxis_1[iTrk][2][0] =  4.5812504e-07\n",
      "minorAxis_2[iTrk][0][0] =  6.0408506\n",
      "minorAxis_2[iTrk][1][0] =  16.602718\n",
      "minorAxis_2[iTrk][2][0] =  0.10317982\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00040561036\n",
      "majorAxis[iTrk][1][0] =  0.00014461782\n",
      "majorAxis[iTrk][2][0] =  0.0872241\n",
      "minorAxis_1[iTrk][0][0] =  -5.933496\n",
      "minorAxis_1[iTrk][1][0] =  -16.641706\n",
      "minorAxis_1[iTrk][2][0] =  1.0720762e-08\n",
      "minorAxis_2[iTrk][0][0] =  -16.641502\n",
      "minorAxis_2[iTrk][1][0] =  5.9334235\n",
      "minorAxis_2[iTrk][2][0] =  -0.0872241\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00038461428\n",
      "majorAxis[iTrk][1][0] =  -3.4232737e-05\n",
      "majorAxis[iTrk][2][0] =  0.08259597\n",
      "minorAxis_1[iTrk][0][0] =  -1.5663412\n",
      "minorAxis_1[iTrk][1][0] =  -17.598276\n",
      "minorAxis_1[iTrk][2][0] =  3.2106848e-07\n",
      "minorAxis_2[iTrk][0][0] =  -17.598082\n",
      "minorAxis_2[iTrk][1][0] =  1.5663238\n",
      "minorAxis_2[iTrk][2][0] =  0.08259596\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.022277953\n",
      "majorAxis[iTrk][1][0] =  -0.0046837274\n",
      "majorAxis[iTrk][2][0] =  0.63399464\n",
      "minorAxis_1[iTrk][0][0] =  -3.6350286\n",
      "minorAxis_1[iTrk][1][0] =  17.289862\n",
      "minorAxis_1[iTrk][2][0] =  9.566169e-10\n",
      "minorAxis_2[iTrk][0][0] =  17.278727\n",
      "minorAxis_2[iTrk][1][0] =  3.6326876\n",
      "minorAxis_2[iTrk][2][0] =  0.6339946\n",
      "  \n",
      "len(X) =  20000\n",
      "len(Xlist) =  1\n",
      "Loaded dataAA/20K_POCA_kernel_evts_200926.h5 in 31.72 s\n",
      "outer loop X.shape =  (20000, 9, 600)\n",
      "Constructing 2000 event dataset took 0.02154 s\n",
      "x_t.shape =  torch.Size([2000, 9, 600])\n",
      "x_t.shape[0] =  2000\n",
      "x_t.shape[1] =  9\n",
      "x_t.shape =  torch.Size([2000, 9, 600])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "##train_loader = collect_t2kde_data('/share/lazy/pv-finder/20k_evts_for_KDE_learning_200716.h5',\n",
    "train_loader = collect_t2kde_data('/share/lazy/will/data/June30_2020_80k_1.h5', \n",
    "                                    '/share/lazy/will/data/June30_2020_80k_2.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_3.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_4.h5',\n",
    "                             batch_size=batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                          device=device,\n",
    "##                           slice = slice(None,18000)\n",
    "                           )\n",
    "                            \n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## mds no separate validation set yet,\n",
    "val_loader = collect_t2kde_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=batch_size,\n",
    "##                            device=device,\n",
    "                            slice = slice(18000,None)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"1000\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: train = 6667, val = 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2504b459d87e41808d20abec05be0fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', layout=Layout(flex='2'), max=10.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: train = 6667, val = 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5afbbde7a34c01be281d3e066b53ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=6667.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1a72199f43e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                         notebook=True):\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/training_kde.py\u001b[0m in \u001b[0;36mtrainNet\u001b[0;34m(model, optimizer, loss, train_loader, val_loader, n_epochs, notebook, epoch_start)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Run the training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         total_train_loss = train(\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[0mcost_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/training_kde.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss, loader, optimizer, device, progress)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Forward pass, backward pass, optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mloss_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mloss_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/models_kde.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer12new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## produces self.latentChannels*4000 bin feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;31m## at this point x should have the contents expected in the following line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "for result in trainNet(model, optimizer, loss,\n",
    "                        train_loader, val_loader,\n",
    "                        n_epochs, epoch_start=len(results),\n",
    "                        notebook=True):\n",
    "    \n",
    "    results = results.append(pd.Series(result._asdict()), ignore_index=True)\n",
    "    xs = results.index\n",
    "    \n",
    "    # Update the plot above\n",
    "    lines['train'].set_data(results.index,results.cost)\n",
    "    lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "    #filter first cost epoch (can be really large)\n",
    "    max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "    min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "    # The plot limits need updating too\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "    ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "\n",
    "    \n",
    "    # Redraw the figure\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{result.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_hdf(f'{name}_stats.hdf5', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_train_plots(results.index,\n",
    "                 results.cost, results.val,\n",
    "                 results.cost, results.val)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "june2020-gpu",
   "language": "python",
   "name": "june2020-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
