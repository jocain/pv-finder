{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in note\"book, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second (perhaps third) attempt to read in track information and use it to predict the KDE used as input to pv-finder. This time, we are reading in poca KDEs rather than the original KDEs. \n",
    "\n",
    "collectdata_kde_Ellipsoids.py uses poca_z, poca_x, poca_y, and six parameters A, B, C, D, E, and F describing the error ellipsoids are those defined at\n",
    "\n",
    "from https://math.stackexchange.com/questions/1865188/how-to-prove-the-parallel-projection-of-an-ellipsoid-is-an-ellipse\n",
    "\n",
    "Up to translation, a general ellipsoid can be written in the form\n",
    "\n",
    "  洧냢$洧논^2$ +洧냣$洧녽^2$+洧냤$洧녾^2$+2(洧냥洧논洧녽+洧냦洧논洧녾+洧냧洧녽洧녾)=1\n",
    "  \n",
    "for some positive-definite coefficient matrix \n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{ccc}\n",
    "A & D & E \\\\\n",
    "D & B & F \\\\\n",
    "E & F & C \\\\\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "Note that other conventions use a similarly named set of parameters with D, E, and and F denoting the coefficients of different combinations of $ x y $, etc., or without the factor of 2 in front of the cross-terms.  However, this is the convention we are using for pv-finder related work, as of early November, 20020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  1 09:24:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:18:00.0 Off |                  N/A |\n",
      "| 29%   45C    P8    42W / 250W |   4984MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 36%   54C    P2    94W / 250W |   4675MiB / 11019MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 3090    On   | 00000000:AF:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8    30W / 350W |  18913MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    174932      C   ...s/june2020-gpu/bin/python      999MiB |\n",
      "|    0   N/A  N/A    239812      C   .../envs/will-gpu/bin/python      155MiB |\n",
      "|    0   N/A  N/A    271611      C   ...s/june2020-gpu/bin/python     3827MiB |\n",
      "|    1   N/A  N/A    184455      C   ...s/june2020-gpu/bin/python     4517MiB |\n",
      "|    1   N/A  N/A    239812      C   .../envs/will-gpu/bin/python      155MiB |\n",
      "|    2   N/A  N/A     50582      C   ...s/june2020-gpu/bin/python     1485MiB |\n",
      "|    2   N/A  N/A    239812      C   .../envs/will-gpu/bin/python    17425MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is first attempt to read in track information and use it to predict the KDE used as input to PvFinder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "##from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "\n",
    "# Name is the output file name\n",
    "\n",
    "\n",
    "##  201019  mds\n",
    "folder = '06November_testing_DirtyDozen_first_learning_iterC_5000epochs_1em5'\n",
    "name   = folder\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = 'ML/' + folder\n",
    "output = Path(folder)\n",
    "\n",
    "\n",
    "# Size of batches\n",
    "batch_size = 64\n",
    "# How fast to learn\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From model/collectdata.py\n",
    "##from model.collectdata_kde_B import collect_t2kde_data\n",
    "## collectdata_kde_C should use the new poca KDE rather than the original kernel KDE\n",
    "from model.collectdata_kde_Ellipsoids import collect_t2kde_data\n",
    "\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "## kde_loss_D includes botha ratio term and a chisq term, 98% ave_chisq\n",
    "## kde_loss_E adds a chi^4 term to the kde_loss_D return value\n",
    "## this is intended to emphasize the importance of values significantly different than zero\n",
    "from model.kde_loss_E import Loss\n",
    "\n",
    "##  TracksToKDE_Ellipsoids_SevenLayerCake has 7 hidden layers producing the 4000-bin KDE historgram\n",
    "##  It takes 9 input features (pocca centers + (A,B,C,D,E,F) . \n",
    "from model.models_kde import TracksToKDE_Ellipsoids_DirtyDozen as Model\n",
    "\n",
    "\n",
    "from model.training_kde import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(1)\n",
    "##device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "##if torch.cuda.device_count() > 1:\n",
    "##    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct, child =  0    Linear(in_features=9, out_features=20, bias=True)\n",
      "ct, child =  1    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  2    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  3    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  4    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  5    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  6    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  7    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  8    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  9    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  10    Linear(in_features=20, out_features=20, bias=True)\n",
      "ct, child =  11    Linear(in_features=20, out_features=4000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "## a comment on the web at https://pytorch.org/docs/stable/optim.html says\n",
    "\"\"\"\n",
    "If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. \n",
    "Parameters of a model after .cuda() will be different objects with those before the call.\n",
    "\n",
    "In general, you should make sure that optimized parameters live in consistent locations when \n",
    "optimizers are constructed and used.\n",
    "\"\"\"\n",
    "## so move this here (although we are using model.to(device) not explicitly using .cuda()\n",
    "\n",
    "nOut1 = 20\n",
    "nOut2 = 20\n",
    "nOut3 = 20\n",
    "nOut4 = 20\n",
    "nOut5 = 20\n",
    "nOut6 = 20\n",
    "nOut7 = 20\n",
    "nOut8 = 20\n",
    "nOut9 = 20\n",
    "nOut10 = 20\n",
    "nOut11 = 20\n",
    "model = Model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11)\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "  print('ct, child = ',ct, \"  \", child)\n",
    "  if ct < 0:\n",
    "    print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False \n",
    "  ct += 1\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "##  loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "loss = Loss(epsilon=3e-6, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "##optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  ML/06November_testing_DirtyDozen_first_learning_iterC_5000epochs_1em5\n",
      "for model_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12.weight\n",
      "index, k =   23    layer12.bias\n",
      " \n",
      "  for pretrained_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12.weight\n",
      "index, k =   23    layer12.bias\n",
      "pretrained_dict iterated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('output = ',output)\n",
    "##print('oldOutput = ',oldOutput)\n",
    "##  use the first four layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "model_dict = model.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_dict\")\n",
    "index = 0\n",
    "for k,v in model_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "##    print(\"value = \", v)\n",
    " \n",
    "updated_dict = model_dict\n",
    "##print(\"updated_dict = \",updated_dict)\n",
    "## when starting \"ab initio\", reduce biases as the bias gets summed for each track\n",
    "## contributing to the predicted KDE\n",
    "updated_dict[\"layer1.bias\"] = 0.005*model_dict[\"layer1.bias\"]\n",
    "updated_dict[\"layer2.bias\"] = 0.005*model_dict[\"layer2.bias\"]\n",
    "updated_dict[\"layer3.bias\"] = 0.005*model_dict[\"layer3.bias\"]\n",
    "updated_dict[\"layer4.bias\"] = 0.005*model_dict[\"layer4.bias\"]\n",
    "updated_dict[\"layer5.bias\"] = 0.005*model_dict[\"layer5.bias\"]\n",
    "updated_dict[\"layer6.bias\"] = 0.005*model_dict[\"layer6.bias\"]\n",
    "updated_dict[\"layer7.bias\"] = 0.005*model_dict[\"layer7.bias\"]\n",
    "updated_dict[\"layer8.bias\"] = 0.005*model_dict[\"layer8.bias\"]\n",
    "updated_dict[\"layer9.bias\"] = 0.005*model_dict[\"layer9.bias\"]\n",
    "updated_dict[\"layer10.bias\"] = 0.005*model_dict[\"layer10.bias\"]\n",
    "updated_dict[\"layer11.bias\"] = 0.005*model_dict[\"layer11.bias\"]\n",
    "\n",
    "model.load_state_dict(updated_dict,strict=False)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "##print(\"updated model_dict = \",model_dict)\n",
    "\n",
    "## print(\" \\n\",\"  for pretrained_dict\")\n",
    "## index = 0\n",
    "##for k,v in pretrained_dict.items():\n",
    "##    print(\"index, k =  \",index,\"  \",k)\n",
    "##    index = index+1\n",
    "## mds  \n",
    "\n",
    "##pretrained_dict = torch.load('ML/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50_final.pyt')\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "##pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "##print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "##model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "##model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n",
    "## print('model_dict =    ', model_dict)\n",
    "\n",
    "## pretrained_dict = torch.load('ML/19October_testing_loss_C_500epochs_more_learning/19October_testing_loss_C_500epochs_more_learning_final.pyt')\n",
    "## pretrained_dict = torch.load('ML/24October_testing_SevenLayerCake_first_learning_50epochs/24October_testing_SevenLayerCake_first_learning_50epochs_44.pyt')\n",
    "\n",
    "##pretrained_dict = torch.load('ML/24October_testing_SevenLayerCake_first_learning_next1000epochs/24October_testing_SevenLayerCake_first_learning_next1000epochs_976.pyt')\n",
    "## pretrained_dict = torch.load('ML/24October_testing_SevenLayerCake_first_learning_iter4_2500epochs_1em5/24October_testing_SevenLayerCake_first_learning_iter4_2500epochs_1em5_final.pyt')\n",
    "## pretrained_dict = torch.load('ML/25October_testing_SevenLayerCake_first_learning_iter0_1000epochs_lossE/25October_testing_SevenLayerCake_first_learning_iter0_1000epochs_lossE_503.pyt')\n",
    "\n",
    "\n",
    "## pretrained_dict = torch.load('ML/25October_testing_SevenLayerCake_first_learning_iter0_1000epochs_lossE/25October_testing_SevenLayerCake_first_learning_iter0_1000epochs_lossE_final.pyt')\n",
    "\n",
    "## pretrained_dict = torch.load('ML/25October_testing_SevenLayerCake_first_learning_iter2_100epochs_lossE/25October_testing_SevenLayerCake_first_learning_iter2_100epochs_lossE_final.pyt')\n",
    "\n",
    "## pretrained_dict = torch.load('ML/25October_testing_SevenLayerCake_first_learning_iter2_2nd_100epochs_lossE_Adam/25October_testing_SevenLayerCake_first_learning_iter2_2nd_100epochs_lossE_Adam_final.pyt')\n",
    "\n",
    "## pretrained_dict = torch.load('ML/25October_testing_SevenLayerCake_first_learning_iter3_4000epochs_lossE_Adam/25October_testing_SevenLayerCake_first_learning_iter3_4000epochs_lossE_Adam_final.pyt')\n",
    "\n",
    "##  results from the previous model were fluctuating, so choose epoch with relatively low costs\n",
    "\n",
    "##pretrained_dict = torch.load('ML/27October_testing_DirtyDozen_first_learning_iter0_250epochs_1em3/27October_testing_DirtyDozen_first_learning_iter0_250epochs_1em3_220.pyt')\n",
    "\n",
    "##  the next model had fluctuations near the end, but the final epoch is within striking distance of the lowest cost\n",
    "pretrained_dict = torch.load('ML/06November_testing_DirtyDozen_first_learning_iterB_20epochs_1em6/06November_testing_DirtyDozen_first_learning_iterB_20epochs_1em6_final.pyt')\n",
    "print(\" \")\n",
    "print(\"  for pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    " \n",
    "\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "model.load_state_dict(pretrained_dict,strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "pocaMx.shape =  (20000,)\n",
      "nEvts =  20000\n",
      "len(pocaMx[0]) =  211\n",
      "len(pocaMx[1]) =  21\n",
      "len(pocaMx[2]) =  20\n",
      "len(pocaMx[3]) =  198\n",
      "len(pocaMx[4]) =  233\n",
      "majorAxis.shape =  (20000, 3)\n",
      "minorAxis_1.shape =  (20000, 3)\n",
      "minorAxis_2.shape =  (20000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  20000\n",
      " iEvt, nTrks =  0 211\n",
      " iEvt, nTrks =  1 21\n",
      " iEvt, nTrks =  2 20\n",
      " iEvt, nTrks =  3 198\n",
      " iEvt, nTrks =  4 233\n",
      " iEvt, nTrks =  5 85\n",
      " iEvt, nTrks =  6 223\n",
      " iEvt, nTrks =  7 425\n",
      " iEvt, nTrks =  8 252\n",
      " iEvt, nTrks =  9 169\n",
      "A.shape =  (20000,)\n",
      "majorAxis[iTrk][0][0] =  -0.00023452607\n",
      "majorAxis[iTrk][1][0] =  -0.00047206535\n",
      "majorAxis[iTrk][2][0] =  0.096502915\n",
      "minorAxis_1[iTrk][0][0] =  -15.822749\n",
      "minorAxis_1[iTrk][1][0] =  7.8608756\n",
      "minorAxis_1[iTrk][2][0] =  -2.6228399e-08\n",
      "minorAxis_2[iTrk][0][0] =  7.860759\n",
      "minorAxis_2[iTrk][1][0] =  15.822513\n",
      "minorAxis_2[iTrk][2][0] =  0.096502915\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.37655562\n",
      "majorAxis[iTrk][1][0] =  0.2768704\n",
      "majorAxis[iTrk][2][0] =  2.8546858\n",
      "minorAxis_1[iTrk][0][0] =  -10.466048\n",
      "minorAxis_1[iTrk][1][0] =  -14.234274\n",
      "minorAxis_1[iTrk][2][0] =  2.2974699e-11\n",
      "minorAxis_2[iTrk][0][0] =  -14.04724\n",
      "minorAxis_2[iTrk][1][0] =  10.328527\n",
      "minorAxis_2[iTrk][2][0] =  -2.8546853\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.024279848\n",
      "majorAxis[iTrk][1][0] =  0.0019689242\n",
      "majorAxis[iTrk][2][0] =  0.65580803\n",
      "minorAxis_1[iTrk][0][0] =  -1.4280497\n",
      "minorAxis_1[iTrk][1][0] =  -17.610037\n",
      "minorAxis_1[iTrk][2][0] =  -6.123401e-10\n",
      "minorAxis_2[iTrk][0][0] =  -17.597902\n",
      "minorAxis_2[iTrk][1][0] =  1.4270656\n",
      "minorAxis_2[iTrk][2][0] =  -0.6558081\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.007825993\n",
      "majorAxis[iTrk][1][0] =  0.004052097\n",
      "majorAxis[iTrk][2][0] =  0.3945435\n",
      "minorAxis_1[iTrk][0][0] =  8.123606\n",
      "minorAxis_1[iTrk][1][0] =  15.689478\n",
      "minorAxis_1[iTrk][2][0] =  -2.4940747e-10\n",
      "minorAxis_2[iTrk][0][0] =  15.685566\n",
      "minorAxis_2[iTrk][1][0] =  -8.12158\n",
      "minorAxis_2[iTrk][2][0] =  0.3945435\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0046102717\n",
      "majorAxis[iTrk][1][0] =  -0.0016007021\n",
      "majorAxis[iTrk][2][0] =  0.29361814\n",
      "minorAxis_1[iTrk][0][0] =  -5.794979\n",
      "minorAxis_1[iTrk][1][0] =  -16.690445\n",
      "minorAxis_1[iTrk][2][0] =  2.4897104e-09\n",
      "minorAxis_2[iTrk][0][0] =  -16.688139\n",
      "minorAxis_2[iTrk][1][0] =  5.794179\n",
      "minorAxis_2[iTrk][2][0] =  0.2936181\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00020041714\n",
      "majorAxis[iTrk][1][0] =  0.00010468164\n",
      "majorAxis[iTrk][2][0] =  0.06320469\n",
      "minorAxis_1[iTrk][0][0] =  8.179679\n",
      "minorAxis_1[iTrk][1][0] =  15.660318\n",
      "minorAxis_1[iTrk][2][0] =  7.40176e-08\n",
      "minorAxis_2[iTrk][0][0] =  15.660218\n",
      "minorAxis_2[iTrk][1][0] =  -8.179626\n",
      "minorAxis_2[iTrk][2][0] =  0.06320469\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00020603223\n",
      "majorAxis[iTrk][1][0] =  -0.0005662605\n",
      "majorAxis[iTrk][2][0] =  0.10317981\n",
      "minorAxis_1[iTrk][0][0] =  -16.603\n",
      "minorAxis_1[iTrk][1][0] =  6.040953\n",
      "minorAxis_1[iTrk][2][0] =  4.5812504e-07\n",
      "minorAxis_2[iTrk][0][0] =  6.0408506\n",
      "minorAxis_2[iTrk][1][0] =  16.602718\n",
      "minorAxis_2[iTrk][2][0] =  0.10317982\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00040561036\n",
      "majorAxis[iTrk][1][0] =  0.00014461782\n",
      "majorAxis[iTrk][2][0] =  0.0872241\n",
      "minorAxis_1[iTrk][0][0] =  -5.933496\n",
      "minorAxis_1[iTrk][1][0] =  -16.641706\n",
      "minorAxis_1[iTrk][2][0] =  1.0720762e-08\n",
      "minorAxis_2[iTrk][0][0] =  -16.641502\n",
      "minorAxis_2[iTrk][1][0] =  5.9334235\n",
      "minorAxis_2[iTrk][2][0] =  -0.0872241\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00038461428\n",
      "majorAxis[iTrk][1][0] =  -3.4232737e-05\n",
      "majorAxis[iTrk][2][0] =  0.08259597\n",
      "minorAxis_1[iTrk][0][0] =  -1.5663412\n",
      "minorAxis_1[iTrk][1][0] =  -17.598276\n",
      "minorAxis_1[iTrk][2][0] =  3.2106848e-07\n",
      "minorAxis_2[iTrk][0][0] =  -17.598082\n",
      "minorAxis_2[iTrk][1][0] =  1.5663238\n",
      "minorAxis_2[iTrk][2][0] =  0.08259596\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.022277953\n",
      "majorAxis[iTrk][1][0] =  -0.0046837274\n",
      "majorAxis[iTrk][2][0] =  0.63399464\n",
      "minorAxis_1[iTrk][0][0] =  -3.6350286\n",
      "minorAxis_1[iTrk][1][0] =  17.289862\n",
      "minorAxis_1[iTrk][2][0] =  9.566169e-10\n",
      "minorAxis_2[iTrk][0][0] =  17.278727\n",
      "minorAxis_2[iTrk][1][0] =  3.6326876\n",
      "minorAxis_2[iTrk][2][0] =  0.6339946\n",
      "  \n",
      "len(X) =  20000\n",
      "len(Xlist) =  1\n",
      "Loaded dataAA/20K_POCA_kernel_evts_200926.h5 in 31.25 s\n",
      "outer loop X.shape =  (20000, 9, 600)\n",
      "Constructing 18000 event dataset took 0.473 s\n",
      "x_t.shape =  torch.Size([18000, 9, 600])\n",
      "x_t.shape[0] =  18000\n",
      "x_t.shape[1] =  9\n",
      "x_t.shape =  torch.Size([18000, 9, 600])\n",
      "Loading data...\n",
      "pocaMx.shape =  (20000,)\n",
      "nEvts =  20000\n",
      "len(pocaMx[0]) =  211\n",
      "len(pocaMx[1]) =  21\n",
      "len(pocaMx[2]) =  20\n",
      "len(pocaMx[3]) =  198\n",
      "len(pocaMx[4]) =  233\n",
      "majorAxis.shape =  (20000, 3)\n",
      "minorAxis_1.shape =  (20000, 3)\n",
      "minorAxis_2.shape =  (20000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  20000\n",
      " iEvt, nTrks =  0 211\n",
      " iEvt, nTrks =  1 21\n",
      " iEvt, nTrks =  2 20\n",
      " iEvt, nTrks =  3 198\n",
      " iEvt, nTrks =  4 233\n",
      " iEvt, nTrks =  5 85\n",
      " iEvt, nTrks =  6 223\n",
      " iEvt, nTrks =  7 425\n",
      " iEvt, nTrks =  8 252\n",
      " iEvt, nTrks =  9 169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "##train_loader = collect_t2kde_data('/share/lazy/pv-finder/20k_evts_for_KDE_learning_200716.h5',\n",
    "train_loader = collect_t2kde_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "##train_loader = collect_t2kde_data('/share/lazy/pv-finder/test_data_for_KDE_learning_BastilleDay20.h5',\n",
    "                            batch_size=batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "                           device=device,\n",
    "                           slice = slice(None,18000)\n",
    "                           )\n",
    "                            \n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## mds no separate validation set yet,\n",
    "val_loader = collect_t2kde_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=batch_size,\n",
    "                            device=device,\n",
    "                            slice = slice(18000,None)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    counter = 0\n",
    "    event = 0\n",
    "    print(\"train_loader = \",train_loader)\n",
    "    for inputs, labels in train_loader:\n",
    "##        print(\"counter = \",counter)\n",
    "##        print(\"inputs = \",inputs)\n",
    "        print(\"inputs.shape = \",inputs.shape)\n",
    "        if inputs.device != device:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "        outputs = model(inputs)\n",
    "##        print(\"outputs.shape = \",outputs.shape)\n",
    "        nEvts = outputs.shape[0]\n",
    "        for iEvt in range(nEvts):\n",
    "            y_pred = outputs[iEvt,:]\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            \n",
    "            event = event +1\n",
    "##            print(\"event = \",event)\n",
    "            if (event<5):\n",
    "                plt.figure()\n",
    "                plt.plot(y_pred[0:50])\n",
    "                plt.show()\n",
    "                \n",
    "##                print(\"  point AA \")\n",
    "                features = inputs[iEvt,:]\n",
    "                features = features[np.newaxis,:,:]\n",
    "                \n",
    "                \n",
    "                print(\"features.shape = \",features.shape)\n",
    "                \n",
    "                output_A = model(features)\n",
    "                y_prime = output_A[0,:]\n",
    "                y_prime = y_prime.cpu().numpy()\n",
    "                plt.figure()\n",
    "                plt.plot(y_prime[0:50], color=\"r\")\n",
    "                plt.show()\n",
    "                \n",
    "            \n",
    "\n",
    "##        print(\"nEvts = \",nEvts)\n",
    "        \n",
    "        counter = counter+1\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in trainNet(model, optimizer, loss,\n",
    "                        train_loader, val_loader,\n",
    "                        n_epochs, epoch_start=len(results),\n",
    "                        notebook=True):\n",
    "    \n",
    "    results = results.append(pd.Series(result._asdict()), ignore_index=True)\n",
    "    xs = results.index\n",
    "    \n",
    "    # Update the plot above\n",
    "    lines['train'].set_data(results.index,results.cost)\n",
    "    lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "    #filter first cost epoch (can be really large)\n",
    "    max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "    min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "    # The plot limits need updating too\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "    ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "\n",
    "    \n",
    "    # Redraw the figure\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{result.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_hdf(f'{name}_stats.hdf5', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_train_plots(results.index,\n",
    "                 results.cost, results.val,\n",
    "                 results.cost, results.val)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "june2020-gpu",
   "language": "python",
   "name": "june2020-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
