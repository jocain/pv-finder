{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in note\"book, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second attempt to read in track information and use it to predict the KDE used as input to PvFinder. This time, we are reading in poca KDEs rather than the original KDEs. \n",
    "\n",
    "collectdata_kde_C.py uses poca_z, poca_x, poca_y, major_axis_x, major_axis_y, and major_axis_z as the six track parameters (for the moment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 25 16:28:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 20%   36C    P0    32W / 250W |      0MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 22%   37C    P0    34W / 250W |      0MiB / 12066MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is first attempt to read in track information and use it to predict the KDE used as input to PvFinder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "##from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "# Name is the output file name\n",
    "\n",
    "\n",
    "##  201027 -- about to go to bed, so try 2500 epochs with lr = 1e55\n",
    "##  previous iteration had l4 = 3e-5 and cost dropped almost linearly\n",
    "##  for 100 epochs -- final training costs ~ 2.02, validation cost ~ 2.01\n",
    "\n",
    "## for iter 4, try 10 epochs with lr = 3e-6\n",
    "## usually have a big jump down at epoch 0; want to try a\n",
    "## small number of epochs per iteration and see what happens (iter4: 10 epochs gave\n",
    "## traiing cost dropping from 1.54 to 1.50 immediately, then dropping very slowly)\n",
    "\n",
    "## For iter12, let's try increaseing the learning rate from 1em5 to 1p5em5 as the\n",
    "## training costs have been dropping almost \"linearlY\" on the semilog plot\n",
    "## for several iterations, suggesting that we can afford to take the risk\n",
    "## For good measure, we'll try this for 10 epochs as a test \n",
    "##  Iter12 seems to have worked we4ll, so start iter13 for 60 epochs\n",
    "## so it will run over night\n",
    "folder = '25Jan_DDplus_loss_Ba_iter16_floatAll_5epochs_1p5em5_1xwill_refactor'\n",
    "name   = folder\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = 'ML/' + folder\n",
    "output = Path(folder)\n",
    "\n",
    "\n",
    "# Size of batches\n",
    "batch_size = 48 ## batch_size = 24 ---> 4763MiB / 12066MiB on Titan V\n",
    "# How fast to learn\n",
    "learning_rate = 1.5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b502b288e7f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m##  It takes 9 input features (pocca centers + (A,B,C,D,E,F) .\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m##from model.models_kde import TracksToKDE_Ellipsoids_DDplus as Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwill_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTracksToKDE_Ellipsoids_DDplus\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/will_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPARAM_EFF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBaseTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "# From model/collectdata.py\n",
    "##from model.collectdata_kde_B import collect_t2kde_data\n",
    "## collectdata_kde_C should use the new poca KDE rather than the original kernel KDE\n",
    "from model.collectdata_kde_Ellipsoids import collect_t2kde_data\n",
    "\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "## kde_loss_D includes botha ratio term and a chisq term, 98% ave_chisq\n",
    "## kde_loss_E adds a chi^4 term to the kde_loss_D return value\n",
    "## this is intended to emphasize the importance of values significantly different than zero\n",
    "from model.kde_loss_Ba import Loss\n",
    "\n",
    "##  TracksToKDE_Ellipsoids_SevenLayerCake has 7 hidden layers producing the 4000-bin KDE historgram\n",
    "##  It takes 9 input features (pocca centers + (A,B,C,D,E,F) . \n",
    "##from model.models_kde import TracksToKDE_Ellipsoids_DDplus as Model\n",
    "from model.will_model import TracksToKDE_Ellipsoids_DDplus as Model\n",
    "\n",
    "\n",
    "from model.training_kde import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_gpu(2)\n",
    "##device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "##if torch.cuda.device_count() > 1:\n",
    "##    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a comment on the web at https://pytorch.org/docs/stable/optim.html says\n",
    "\"\"\"\n",
    "If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. \n",
    "Parameters of a model after .cuda() will be different objects with those before the call.\n",
    "\n",
    "In general, you should make sure that optimized parameters live in consistent locations when \n",
    "optimizers are constructed and used.\n",
    "\"\"\"\n",
    "## so move this here (although we are using model.to(device) not explicitly using .cuda()\n",
    "\n",
    "nOut1 = 50\n",
    "nOut2 = 50\n",
    "nOut3 = 50\n",
    "nOut4 = 50\n",
    "nOut5 = 50\n",
    "nOut6 = 50\n",
    "nOut7 = 50\n",
    "nOut8 = 50\n",
    "nOut9 = 50\n",
    "nOut10 = 50\n",
    "nOut11 = 50\n",
    "latentChannels = 4\n",
    "model = Model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11,latentChannels)\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "  print('ct, child = ',ct, \"  \", child)\n",
    "  if ct < 0:\n",
    "    print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False \n",
    "  ct += 1\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "##  loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "##loss = Loss(epsilon=3e-5, debug=False)\n",
    "loss = Loss(epsilon=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "##optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('output = ',output)\n",
    "##print('oldOutput = ',oldOutput)\n",
    "##  use the first four layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "model_dict = model.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_dict\")\n",
    "index = 0\n",
    "for k,v in model_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "##    print(\"value = \", v)\n",
    " \n",
    "updated_dict = model_dict\n",
    "##print(\"updated_dict = \",updated_dict)\n",
    "## when starting \"ab initio\", reduce biases as the bias gets summed for each track\n",
    "## contributing to the predicted KDE\n",
    "updated_dict[\"layer1.bias\"] = 0.005*model_dict[\"layer1.bias\"]\n",
    "updated_dict[\"layer2.bias\"] = 0.005*model_dict[\"layer2.bias\"]\n",
    "updated_dict[\"layer3.bias\"] = 0.005*model_dict[\"layer3.bias\"]\n",
    "updated_dict[\"layer4.bias\"] = 0.005*model_dict[\"layer4.bias\"]\n",
    "updated_dict[\"layer5.bias\"] = 0.005*model_dict[\"layer5.bias\"]\n",
    "updated_dict[\"layer6.bias\"] = 0.005*model_dict[\"layer6.bias\"]\n",
    "updated_dict[\"layer7.bias\"] = 0.005*model_dict[\"layer7.bias\"]\n",
    "updated_dict[\"layer8.bias\"] = 0.005*model_dict[\"layer8.bias\"]\n",
    "updated_dict[\"layer9.bias\"] = 0.005*model_dict[\"layer9.bias\"]\n",
    "updated_dict[\"layer10.bias\"] = 0.005*model_dict[\"layer10.bias\"]\n",
    "updated_dict[\"layer11.bias\"] = 0.005*model_dict[\"layer11.bias\"]\n",
    "\n",
    "model.load_state_dict(updated_dict,strict=False)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "##print(\"updated model_dict = \",model_dict)\n",
    "\n",
    "## print(\" \\n\",\"  for pretrained_dict\")\n",
    "## index = 0\n",
    "##for k,v in pretrained_dict.items():\n",
    "##    print(\"index, k =  \",index,\"  \",k)\n",
    "##    index = index+1\n",
    "## mds  \n",
    "\n",
    "##pretrained_dict = torch.load('ML/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50_final.pyt')\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "##pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "##print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "##model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "##model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n",
    "## print('model_dict =    ', model_dict)\n",
    "\n",
    "## finished at training cost = 1.46, validation cost = 1.50\n",
    "##d_folder = '25December__DDplus_loss_Ba_iter7_floatAll_800epochs_4em6'\n",
    "d_folder = '22Jan_DDplus_loss_Ba_iter15_floatAll_100epochs_1p5em5_4xwill'\n",
    "d_name = d_folder\n",
    "suffix = 'final'\n",
    "dict_name = 'ML/' + d_folder + '/' + d_name + '_'+ suffix + '.pyt'\n",
    "print('dict_name = ',dict_name)\n",
    "pretrained_dict = torch.load(dict_name)\n",
    "\n",
    "print(\" \")\n",
    "print(\"  for pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    " \n",
    "\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "##train_loader = collect_t2kde_data('/share/lazy/pv-finder/20k_evts_for_KDE_learning_200716.h5',\n",
    "train_loader = collect_t2kde_data('/share/lazy/will/data/June30_2020_80k_1.h5', \n",
    "                                    '/share/lazy/will/data/June30_2020_80k_2.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_3.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_4.h5',\n",
    "                             batch_size=batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                          device=device,\n",
    "##                           slice = slice(None,18000)\n",
    "                           )\n",
    "                            \n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## mds no separate validation set yet,\n",
    "\n",
    "## For iter12, change slice(18000,None) to slice(10000,None)\n",
    "## First, we'll see if this changes the validation cost significantly\n",
    "##  Second, we will see if this reduces the validation cost fluctuations\n",
    "val_loader = collect_t2kde_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=batch_size,\n",
    "##                            device=device,\n",
    "                            slice = slice(10000,None)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in trainNet(model, optimizer, loss,\n",
    "                        train_loader, val_loader,\n",
    "                        n_epochs, epoch_start=len(results),\n",
    "                        notebook=True):\n",
    "    \n",
    "    results = results.append(pd.Series(result._asdict()), ignore_index=True)\n",
    "    xs = results.index\n",
    "    \n",
    "    # Update the plot above\n",
    "    lines['train'].set_data(results.index,results.cost)\n",
    "    lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "    #filter first cost epoch (can be really large)\n",
    "    max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "    min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "    # The plot limits need updating too\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "    ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "\n",
    "    \n",
    "    # Redraw the figure\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{result.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_hdf(f'{name}_stats.hdf5', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_train_plots(results.index,\n",
    "                 results.cost, results.val,\n",
    "                 results.cost, results.val)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
