{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in note\"book, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an iterated attempt to calculate the KDE used as input to PvFinder. We are reading in  a poca KDE (KDE_A to start) rather than the original KDEs. \n",
    "\n",
    "The starting point here is a trained version of TracksToKDE_DD (fully connected layers only) to which we add some convolutional layers and a final fully connected layer (because only CNN stalls).\n",
    "\n",
    "collectdata_kde_C.py uses poca_z, poca_x, poca_y, major_axis_x, major_axis_y, and major_axis_z as the six track parameters (for the moment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 18 20:44:45 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN V             Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 48%   66C    P2   113W / 250W |   3530MiB / 12066MiB |     97%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla P100-PCIE...  Off  | 00000000:83:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN V             Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 28%   36C    P8    25W / 250W |     12MiB / 12066MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      4892      C   ...a/conda/envs/goofit-june2020/bin/python  2423MiB |\r\n",
      "|    0     30329      C   ...a/conda/envs/goofit-june2020/bin/python  1095MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is first attempt to read in track information and use it to predict the KDE used as input to PvFinder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "##from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "\n",
    "# Name is the output file name\n",
    "\n",
    "\n",
    "##  201027 -- about to go to bed, so try 2500 epochs with lr = 1e55\n",
    "##  previous iteration had l4 = 3e-5 and cost dropped almost linearly\n",
    "##  for 100 epochs -- final training costs ~ 2.02, validation cost ~ 2.01\n",
    "\n",
    "## for iter 4, try 10 epochs with lr = 3e-6\n",
    "## usually have a big jump down at epoch 0; want to try a\n",
    "## small number of epochs per iteration and see what happens (iter4: 10 epochs gave\n",
    "## traiing cost dropping from 1.54 to 1.50 immediately, then dropping very slowly)\n",
    "folder = '16Jan2021_TracksToKDE_DDplusplus_loss_Ba_iter1_floatAll_300epochs_1em4_4xwill'\n",
    "name   = folder\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = 'ML/' + folder\n",
    "output = Path(folder)\n",
    "\n",
    "\n",
    "# Size of batches\n",
    "##batch_size = 32 ## was 16 ---> on Titan V 5791MiB / 12066MiB; 32 ---> 10481MiB / 12066MiB [when freezing early layers]\n",
    "batch_size = 24 \n",
    "# How fast to learn\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From model/collectdata.py\n",
    "##from model.collectdata_kde_B import collect_t2kde_data\n",
    "## collectdata_kde_C should use the new poca KDE rather than the original kernel KDE\n",
    "from model.collectdata_kde_Ellipsoids import collect_t2kde_data\n",
    "\n",
    "\n",
    "# From model/loss.py\n",
    "### kde_loss_Ba is just a chisq loss, normalized\n",
    "from model.kde_loss_Ba import Loss\n",
    "\n",
    "\n",
    "##  It takes 9 input features (pocca centers + (A,B,C,D,E,F) . \n",
    "from model.models_kde import TracksToKDE_DDplusplus as Model\n",
    "\n",
    "\n",
    "from model.training_kde import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 available GPUs (initially using device 0):\n",
      "  0 TITAN V\n"
     ]
    }
   ],
   "source": [
    "device = select_gpu(0)\n",
    "##device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "##if torch.cuda.device_count() > 1:\n",
    "##    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct, child =  0    Linear(in_features=9, out_features=50, bias=True)\n",
      "ct, child =  1    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  2    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  3    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  4    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  5    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  6    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  7    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  8    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  9    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  10    Linear(in_features=50, out_features=50, bias=True)\n",
      "ct, child =  11    Linear(in_features=50, out_features=32000, bias=True)\n",
      "ct, child =  12    Conv1d(8, 25, kernel_size=(51,), stride=(1,), padding=(25,))\n",
      "ct, child =  13    Conv1d(25, 15, kernel_size=(25,), stride=(1,), padding=(12,))\n",
      "ct, child =  14    Conv1d(15, 1, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "ct, child =  15    Linear(in_features=4000, out_features=4000, bias=True)\n",
      "ct, child =  16    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  17    Dropout(p=0.15, inplace=False)\n",
      "ct, child =  18    Dropout(p=0.15, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "## a comment on the web at https://pytorch.org/docs/stable/optim.html says\n",
    "\"\"\"\n",
    "If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. \n",
    "Parameters of a model after .cuda() will be different objects with those before the call.\n",
    "\n",
    "In general, you should make sure that optimized parameters live in consistent locations when \n",
    "optimizers are constructed and used.\n",
    "\"\"\"\n",
    "## so move this here (although we are using model.to(device) not explicitly using .cuda()\n",
    "\n",
    "nOut1 = 50\n",
    "nOut2 = 50\n",
    "nOut3 = 50\n",
    "nOut4 = 50\n",
    "nOut5 = 50\n",
    "nOut6 = 50\n",
    "nOut7 = 50\n",
    "nOut8 = 50\n",
    "nOut9 = 50\n",
    "nOut10 = 50\n",
    "nOut11 = 50\n",
    "latentChannels = 8\n",
    "model = Model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11,latentChannels)\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "\n",
    "## for iter0 we want the weights from the first 11 fully connected layers from DirtyDozen to be re-used without\n",
    "## floating values (or those of their biases)\n",
    "\n",
    "## for Iter1 let all the weights float\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "  print('ct, child = ',ct, \"  \", child)\n",
    "  if ct < 0:\n",
    "    print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False \n",
    "  ct += 1\n",
    "##  mds 200121 loss = Loss(epsilon=1e-5,coefficient=1.0)\n",
    "##  loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "##loss = Loss(epsilon=3e-5, debug=False)\n",
    "loss = Loss(epsilon=3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "##optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output =  ML/16Jan2021_TracksToKDE_DDplusplus_loss_Ba_iter1_floatAll_300epochs_1em4_4xwill\n",
      "for model_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12new.weight\n",
      "index, k =   23    layer12new.bias\n",
      "index, k =   24    conv1.weight\n",
      "index, k =   25    conv1.bias\n",
      "index, k =   26    conv1A.weight\n",
      "index, k =   27    conv1A.bias\n",
      "index, k =   28    conv2.weight\n",
      "index, k =   29    conv2.bias\n",
      "index, k =   30    fc1.weight\n",
      "index, k =   31    fc1.bias\n",
      "dict_name =  ML/16Jan2021_TracksToKDE_DDplusplus_loss_Ba_iter0_floatAll_5epochs_1em4_4xwill/16Jan2021_TracksToKDE_DDplusplus_loss_Ba_iter0_floatAll_5epochs_1em4_4xwill_final.pyt\n",
      " \n",
      "  for pretrained_dict\n",
      "index, k =   0    layer1.weight\n",
      "index, k =   1    layer1.bias\n",
      "index, k =   2    layer2.weight\n",
      "index, k =   3    layer2.bias\n",
      "index, k =   4    layer3.weight\n",
      "index, k =   5    layer3.bias\n",
      "index, k =   6    layer4.weight\n",
      "index, k =   7    layer4.bias\n",
      "index, k =   8    layer5.weight\n",
      "index, k =   9    layer5.bias\n",
      "index, k =   10    layer6.weight\n",
      "index, k =   11    layer6.bias\n",
      "index, k =   12    layer7.weight\n",
      "index, k =   13    layer7.bias\n",
      "index, k =   14    layer8.weight\n",
      "index, k =   15    layer8.bias\n",
      "index, k =   16    layer9.weight\n",
      "index, k =   17    layer9.bias\n",
      "index, k =   18    layer10.weight\n",
      "index, k =   19    layer10.bias\n",
      "index, k =   20    layer11.weight\n",
      "index, k =   21    layer11.bias\n",
      "index, k =   22    layer12new.weight\n",
      "index, k =   23    layer12new.bias\n",
      "index, k =   24    conv1.weight\n",
      "index, k =   25    conv1.bias\n",
      "index, k =   26    conv1A.weight\n",
      "index, k =   27    conv1A.bias\n",
      "index, k =   28    conv2.weight\n",
      "index, k =   29    conv2.bias\n",
      "index, k =   30    fc1.weight\n",
      "index, k =   31    fc1.bias\n",
      "pretrained_dict iterated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('output = ',output)\n",
    "##print('oldOutput = ',oldOutput)\n",
    "##  use the first four layers from a pre-existing model\n",
    "##  see example at https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "model_dict = model.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_dict\")\n",
    "index = 0\n",
    "for k,v in model_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "##    print(\"value = \", v)\n",
    " \n",
    "updated_dict = model_dict\n",
    "##print(\"updated_dict = \",updated_dict)\n",
    "## when starting \"ab initio\", reduce biases as the bias gets summed for each track\n",
    "## contributing to the predicted KDE\n",
    "updated_dict[\"layer1.bias\"] = 0.005*model_dict[\"layer1.bias\"]\n",
    "updated_dict[\"layer2.bias\"] = 0.005*model_dict[\"layer2.bias\"]\n",
    "updated_dict[\"layer3.bias\"] = 0.005*model_dict[\"layer3.bias\"]\n",
    "updated_dict[\"layer4.bias\"] = 0.005*model_dict[\"layer4.bias\"]\n",
    "updated_dict[\"layer5.bias\"] = 0.005*model_dict[\"layer5.bias\"]\n",
    "updated_dict[\"layer6.bias\"] = 0.005*model_dict[\"layer6.bias\"]\n",
    "updated_dict[\"layer7.bias\"] = 0.005*model_dict[\"layer7.bias\"]\n",
    "updated_dict[\"layer8.bias\"] = 0.005*model_dict[\"layer8.bias\"]\n",
    "updated_dict[\"layer9.bias\"] = 0.005*model_dict[\"layer9.bias\"]\n",
    "updated_dict[\"layer10.bias\"] = 0.005*model_dict[\"layer10.bias\"]\n",
    "updated_dict[\"layer11.bias\"] = 0.005*model_dict[\"layer11.bias\"]\n",
    "\n",
    "model.load_state_dict(updated_dict,strict=False)\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "##print(\"updated model_dict = \",model_dict)\n",
    "\n",
    "## print(\" \\n\",\"  for pretrained_dict\")\n",
    "## index = 0\n",
    "##for k,v in pretrained_dict.items():\n",
    "##    print(\"index, k =  \",index,\"  \",k)\n",
    "##    index = index+1\n",
    "## mds  \n",
    "\n",
    "##pretrained_dict = torch.load('ML/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50/29July2020_Trks_to_KDE_C_lossB_100epochs_b64_1m3_nOut_50x50_final.pyt')\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "##pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "##print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "##model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "##model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n",
    "## print('model_dict =    ', model_dict)\n",
    "\n",
    "## finished at training cost = 1.46, validation cost = 1.50\n",
    "d_folder = '16Jan2021_TracksToKDE_DDplusplus_loss_Ba_iter0_floatAll_5epochs_1em4_4xwill'\n",
    "d_name = d_folder\n",
    "suffix = 'final'\n",
    "dict_name = 'ML/' + d_folder + '/' + d_name + '_'+ suffix + '.pyt'\n",
    "print('dict_name = ',dict_name)\n",
    "pretrained_dict = torch.load(dict_name)\n",
    "\n",
    "print(\" \")\n",
    "print(\"  for pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    " \n",
    "\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_dict.update(pretrained_dict) \n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "model.load_state_dict(pretrained_dict,strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "pocaMx.shape =  (80000,)\n",
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  199\n",
      "len(pocaMx[1]) =  25\n",
      "len(pocaMx[2]) =  369\n",
      "len(pocaMx[3]) =  143\n",
      "len(pocaMx[4]) =  160\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 199\n",
      " iEvt, nTrks =  1 25\n",
      " iEvt, nTrks =  2 369\n",
      " iEvt, nTrks =  3 143\n",
      " iEvt, nTrks =  4 160\n",
      " iEvt, nTrks =  5 260\n",
      " iEvt, nTrks =  6 237\n",
      " iEvt, nTrks =  7 327\n",
      " iEvt, nTrks =  8 178\n",
      " iEvt, nTrks =  9 106\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  0.00045611936\n",
      "majorAxis[iTrk][1][0] =  -4.8292455e-05\n",
      "majorAxis[iTrk][2][0] =  0.090019904\n",
      "minorAxis_1[iTrk][0][0] =  -1.8602173\n",
      "minorAxis_1[iTrk][1][0] =  -17.569641\n",
      "minorAxis_1[iTrk][2][0] =  4.7891795e-08\n",
      "minorAxis_2[iTrk][0][0] =  -17.569414\n",
      "minorAxis_2[iTrk][1][0] =  1.8601931\n",
      "minorAxis_2[iTrk][2][0] =  0.0900199\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.002360258\n",
      "majorAxis[iTrk][1][0] =  -0.007426616\n",
      "majorAxis[iTrk][2][0] =  0.3710108\n",
      "minorAxis_1[iTrk][0][0] =  -16.837948\n",
      "minorAxis_1[iTrk][1][0] =  -5.3512807\n",
      "minorAxis_1[iTrk][2][0] =  8.157131e-09\n",
      "minorAxis_2[iTrk][0][0] =  -5.3501005\n",
      "minorAxis_2[iTrk][1][0] =  16.834236\n",
      "minorAxis_2[iTrk][2][0] =  0.3710108\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  6.220712e-05\n",
      "majorAxis[iTrk][1][0] =  -4.4594188e-05\n",
      "majorAxis[iTrk][2][0] =  0.036773544\n",
      "minorAxis_1[iTrk][0][0] =  10.293747\n",
      "minorAxis_1[iTrk][1][0] =  14.359369\n",
      "minorAxis_1[iTrk][2][0] =  1.571041e-06\n",
      "minorAxis_2[iTrk][0][0] =  14.359338\n",
      "minorAxis_2[iTrk][1][0] =  -10.293725\n",
      "minorAxis_2[iTrk][2][0] =  -0.03677354\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0033452737\n",
      "majorAxis[iTrk][1][0] =  0.00013028442\n",
      "majorAxis[iTrk][2][0] =  0.2431933\n",
      "minorAxis_1[iTrk][0][0] =  0.6875674\n",
      "minorAxis_1[iTrk][1][0] =  -17.65446\n",
      "minorAxis_1[iTrk][2][0] =  -6.6602626e-09\n",
      "minorAxis_2[iTrk][0][0] =  -17.652788\n",
      "minorAxis_2[iTrk][1][0] =  -0.68750226\n",
      "minorAxis_2[iTrk][2][0] =  0.2431933\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00068196515\n",
      "majorAxis[iTrk][1][0] =  -0.00044562915\n",
      "majorAxis[iTrk][2][0] =  0.119970225\n",
      "minorAxis_1[iTrk][0][0] =  9.664597\n",
      "minorAxis_1[iTrk][1][0] =  -14.790141\n",
      "minorAxis_1[iTrk][2][0] =  1.9819232e-08\n",
      "minorAxis_2[iTrk][0][0] =  -14.789802\n",
      "minorAxis_2[iTrk][1][0] =  -9.664374\n",
      "minorAxis_2[iTrk][2][0] =  -0.11997023\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -8.245073e-05\n",
      "majorAxis[iTrk][1][0] =  0.00015860004\n",
      "majorAxis[iTrk][2][0] =  0.05619731\n",
      "minorAxis_1[iTrk][0][0] =  -15.676071\n",
      "minorAxis_1[iTrk][1][0] =  -8.149452\n",
      "minorAxis_1[iTrk][2][0] =  4.1105773e-07\n",
      "minorAxis_2[iTrk][0][0] =  -8.14941\n",
      "minorAxis_2[iTrk][1][0] =  15.675991\n",
      "minorAxis_2[iTrk][2][0] =  -0.056197315\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.00015151131\n",
      "majorAxis[iTrk][1][0] =  0.00067339616\n",
      "majorAxis[iTrk][2][0] =  0.11042937\n",
      "minorAxis_1[iTrk][0][0] =  17.236937\n",
      "minorAxis_1[iTrk][1][0] =  3.8782384\n",
      "minorAxis_1[iTrk][2][0] =  2.3217373e-08\n",
      "minorAxis_2[iTrk][0][0] =  3.8781626\n",
      "minorAxis_2[iTrk][1][0] =  -17.236599\n",
      "minorAxis_2[iTrk][2][0] =  0.11042936\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -7.577422e-05\n",
      "majorAxis[iTrk][1][0] =  -0.00036802414\n",
      "majorAxis[iTrk][2][0] =  0.08147708\n",
      "minorAxis_1[iTrk][0][0] =  -17.304853\n",
      "minorAxis_1[iTrk][1][0] =  3.5629773\n",
      "minorAxis_1[iTrk][2][0] =  5.80501e-09\n",
      "minorAxis_2[iTrk][0][0] =  3.5629392\n",
      "minorAxis_2[iTrk][1][0] =  17.304668\n",
      "minorAxis_2[iTrk][2][0] =  0.081477076\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00013397264\n",
      "majorAxis[iTrk][1][0] =  0.00094400026\n",
      "majorAxis[iTrk][2][0] =  0.12978876\n",
      "minorAxis_1[iTrk][0][0] =  17.492561\n",
      "minorAxis_1[iTrk][1][0] =  -2.4825466\n",
      "minorAxis_1[iTrk][2][0] =  1.1329301e-08\n",
      "minorAxis_2[iTrk][0][0] =  -2.4824798\n",
      "minorAxis_2[iTrk][1][0] =  -17.492088\n",
      "minorAxis_2[iTrk][2][0] =  0.12978874\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00043501743\n",
      "majorAxis[iTrk][1][0] =  -0.0016521378\n",
      "majorAxis[iTrk][2][0] =  0.17373301\n",
      "minorAxis_1[iTrk][0][0] =  -17.0855\n",
      "minorAxis_1[iTrk][1][0] =  -4.4987106\n",
      "minorAxis_1[iTrk][2][0] =  -7.7275175e-08\n",
      "minorAxis_2[iTrk][0][0] =  -4.4984937\n",
      "minorAxis_2[iTrk][1][0] =  17.084677\n",
      "minorAxis_2[iTrk][2][0] =  0.17373303\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  1\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_1.h5 in 149.5 s\n",
      "pocaMx.shape =  (80000,)\n",
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  222\n",
      "len(pocaMx[1]) =  133\n",
      "len(pocaMx[2]) =  259\n",
      "len(pocaMx[3]) =  114\n",
      "len(pocaMx[4]) =  143\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 222\n",
      " iEvt, nTrks =  1 133\n",
      " iEvt, nTrks =  2 259\n",
      " iEvt, nTrks =  3 114\n",
      " iEvt, nTrks =  4 143\n",
      " iEvt, nTrks =  5 136\n",
      " iEvt, nTrks =  6 397\n",
      " iEvt, nTrks =  7 370\n",
      " iEvt, nTrks =  8 97\n",
      " iEvt, nTrks =  9 67\n",
      "A.shape =  (80000,)\n",
      "majorAxis[iTrk][0][0] =  -0.001036478\n",
      "majorAxis[iTrk][1][0] =  0.0009833863\n",
      "majorAxis[iTrk][2][0] =  0.15887721\n",
      "minorAxis_1[iTrk][0][0] =  -12.160475\n",
      "minorAxis_1[iTrk][1][0] =  -12.817002\n",
      "minorAxis_1[iTrk][2][0] =  0.0\n",
      "minorAxis_2[iTrk][0][0] =  -12.816484\n",
      "minorAxis_2[iTrk][1][0] =  12.159985\n",
      "minorAxis_2[iTrk][2][0] =  -0.15887721\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.0016579849\n",
      "majorAxis[iTrk][1][0] =  0.0020989499\n",
      "majorAxis[iTrk][2][0] =  0.21738033\n",
      "minorAxis_1[iTrk][0][0] =  -13.864233\n",
      "minorAxis_1[iTrk][1][0] =  10.95152\n",
      "minorAxis_1[iTrk][2][0] =  -3.3017489e-09\n",
      "minorAxis_2[iTrk][0][0] =  10.95069\n",
      "minorAxis_2[iTrk][1][0] =  13.863184\n",
      "minorAxis_2[iTrk][2][0] =  -0.21738033\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00012481198\n",
      "majorAxis[iTrk][1][0] =  -0.00028747538\n",
      "majorAxis[iTrk][2][0] =  0.07441149\n",
      "minorAxis_1[iTrk][0][0] =  -16.206305\n",
      "minorAxis_1[iTrk][1][0] =  -7.036224\n",
      "minorAxis_1[iTrk][2][0] =  5.3456716e-08\n",
      "minorAxis_2[iTrk][0][0] =  -7.0361605\n",
      "minorAxis_2[iTrk][1][0] =  16.20616\n",
      "minorAxis_2[iTrk][2][0] =  0.07441148\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.007920195\n",
      "majorAxis[iTrk][1][0] =  -0.009694931\n",
      "majorAxis[iTrk][2][0] =  0.47021532\n",
      "minorAxis_1[iTrk][0][0] =  -13.682467\n",
      "minorAxis_1[iTrk][1][0] =  11.177781\n",
      "minorAxis_1[iTrk][2][0] =  1.8638048e-10\n",
      "minorAxis_2[iTrk][0][0] =  11.173822\n",
      "minorAxis_2[iTrk][1][0] =  13.677622\n",
      "minorAxis_2[iTrk][2][0] =  0.47021535\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  0.00038854493\n",
      "majorAxis[iTrk][1][0] =  0.0009230774\n",
      "majorAxis[iTrk][2][0] =  0.13301943\n",
      "minorAxis_1[iTrk][0][0] =  -16.284061\n",
      "minorAxis_1[iTrk][1][0] =  6.854344\n",
      "minorAxis_1[iTrk][2][0] =  2.2469074e-07\n",
      "minorAxis_2[iTrk][0][0] =  6.8541493\n",
      "minorAxis_2[iTrk][1][0] =  16.283602\n",
      "minorAxis_2[iTrk][2][0] =  -0.13301945\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -5.6093595e-05\n",
      "majorAxis[iTrk][1][0] =  0.000114469876\n",
      "majorAxis[iTrk][2][0] =  0.04745733\n",
      "minorAxis_1[iTrk][0][0] =  15.865369\n",
      "minorAxis_1[iTrk][1][0] =  7.774496\n",
      "minorAxis_1[iTrk][2][0] =  1.8465234e-06\n",
      "minorAxis_2[iTrk][0][0] =  7.774468\n",
      "minorAxis_2[iTrk][1][0] =  -15.865313\n",
      "minorAxis_2[iTrk][2][0] =  0.04745733\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  9.375396e-05\n",
      "majorAxis[iTrk][1][0] =  0.0002926058\n",
      "majorAxis[iTrk][2][0] =  0.07367872\n",
      "minorAxis_1[iTrk][0][0] =  -16.825275\n",
      "minorAxis_1[iTrk][1][0] =  5.390994\n",
      "minorAxis_1[iTrk][2][0] =  -2.1861728e-08\n",
      "minorAxis_2[iTrk][0][0] =  5.3909473\n",
      "minorAxis_2[iTrk][1][0] =  16.825129\n",
      "minorAxis_2[iTrk][2][0] =  -0.07367872\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -1.1543522e-06\n",
      "majorAxis[iTrk][1][0] =  2.8112001e-05\n",
      "majorAxis[iTrk][2][0] =  0.022295665\n",
      "minorAxis_1[iTrk][0][0] =  -17.652967\n",
      "minorAxis_1[iTrk][1][0] =  -0.7248769\n",
      "minorAxis_1[iTrk][2][0] =  1.7815448e-07\n",
      "minorAxis_2[iTrk][0][0] =  -0.7248763\n",
      "minorAxis_2[iTrk][1][0] =  17.652954\n",
      "minorAxis_2[iTrk][2][0] =  -0.022295661\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.2612214\n",
      "majorAxis[iTrk][1][0] =  0.83076316\n",
      "majorAxis[iTrk][2][0] =  3.8745012\n",
      "minorAxis_1[iTrk][0][0] =  -16.85429\n",
      "minorAxis_1[iTrk][1][0] =  -5.299587\n",
      "minorAxis_1[iTrk][2][0] =  2.0865195e-11\n",
      "minorAxis_2[iTrk][0][0] =  -5.1705856\n",
      "minorAxis_2[iTrk][1][0] =  16.444027\n",
      "minorAxis_2[iTrk][2][0] =  -3.874501\n",
      "  \n",
      "majorAxis[iTrk][0][0] =  -0.057592034\n",
      "majorAxis[iTrk][1][0] =  0.06503555\n",
      "majorAxis[iTrk][2][0] =  1.2373537\n",
      "minorAxis_1[iTrk][0][0] =  13.227038\n",
      "minorAxis_1[iTrk][1][0] =  11.713163\n",
      "minorAxis_1[iTrk][2][0] =  1.7679876e-10\n",
      "minorAxis_2[iTrk][0][0] =  11.684402\n",
      "minorAxis_2[iTrk][1][0] =  -13.194561\n",
      "minorAxis_2[iTrk][2][0] =  1.2373537\n",
      "  \n",
      "len(X) =  80000\n",
      "len(Xlist) =  2\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_2.h5 in 158.6 s\n",
      "pocaMx.shape =  (80000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nEvts =  80000\n",
      "len(pocaMx[0]) =  196\n",
      "len(pocaMx[1]) =  35\n",
      "len(pocaMx[2]) =  265\n",
      "len(pocaMx[3]) =  128\n",
      "len(pocaMx[4]) =  124\n",
      "majorAxis.shape =  (80000, 3)\n",
      "minorAxis_1.shape =  (80000, 3)\n",
      "minorAxis_2.shape =  (80000, 3)\n",
      "have entered six_ellipsoid_parameters\n",
      "  \n",
      " \n",
      "  nEvts =  80000\n",
      " iEvt, nTrks =  0 196\n",
      " iEvt, nTrks =  1 35\n",
      " iEvt, nTrks =  2 265\n",
      " iEvt, nTrks =  3 128\n",
      " iEvt, nTrks =  4 124\n",
      " iEvt, nTrks =  5 122\n",
      " iEvt, nTrks =  6 300\n",
      " iEvt, nTrks =  7 179\n",
      " iEvt, nTrks =  8 243\n",
      " iEvt, nTrks =  9 112\n",
      "Loaded /share/lazy/will/data/June30_2020_80k_3.h5 in 111.7 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-09048dc4ab51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m## down performance by about 10%.  So comment out when not needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m##                          device=device,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                            \u001b[0mslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                            )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/collectdata_kde_Ellipsoids.py\u001b[0m in \u001b[0;36mcollect_t2kde_data\u001b[0;34m(batch_size, dtype, device, slice, *files, **kargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix_ellipsoid_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajorAxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminorAxis_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminorAxis_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A.shape = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pv-finder/notebooks/model/ellipsoids.py\u001b[0m in \u001b[0;36msix_ellipsoid_parameters\u001b[0;34m(majorAxis, minorAxis_1, minorAxis_2)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miTrk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnTrks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmag_3_sq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m       \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmag_3_sq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m       \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmag_3_sq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miEvt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTrk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## Training dataset. You can put as many files here as desired.\n",
    "\n",
    "train_loader = collect_t2kde_data('/share/lazy/will/data/June30_2020_80k_1.h5', \n",
    "                                    '/share/lazy/will/data/June30_2020_80k_2.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_3.h5',\n",
    "                                    '/share/lazy/will/data/June30_2020_80k_4.h5',\n",
    "                             batch_size=batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                          device=device,\n",
    "                           slice = slice(None,18000)\n",
    "                           )\n",
    "                            \n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## mds no separate validation set yet,\n",
    "val_loader = collect_t2kde_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=batch_size,\n",
    "##                            device=device,\n",
    "##                            slice = slice(18000,None)\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in trainNet(model, optimizer, loss,\n",
    "                        train_loader, val_loader,\n",
    "                        n_epochs, epoch_start=len(results),\n",
    "                        notebook=True):\n",
    "    \n",
    "    results = results.append(pd.Series(result._asdict()), ignore_index=True)\n",
    "    xs = results.index\n",
    "    \n",
    "    # Update the plot above\n",
    "    lines['train'].set_data(results.index,results.cost)\n",
    "    lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "    #filter first cost epoch (can be really large)\n",
    "    max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "    min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "    # The plot limits need updating too\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "    ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "\n",
    "    \n",
    "    # Redraw the figure\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{result.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_hdf(f'{name}_stats.hdf5', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_train_plots(results.index,\n",
    "                 results.cost, results.val,\n",
    "                 results.cost, results.val)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goofit-june2020",
   "language": "python",
   "name": "goofit-june2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
