{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%matplotlib widget\n",
    "## with %matplotlib notebook: seems to require ipympl as part of environment, either\n",
    "## part of the conda environment or \"pip install ipympl\"\n",
    "## otherwise, does not show ANY plots in notebook, plt.savefig() works\n",
    "%matplotlib notebook  \n",
    "##%matplotlib inline    ## --plt.savefig()  works, but re-sizing does NOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a first attempt to read in track information and use it to predict the the full target histrograms.\n",
    "\n",
    "It will read in the TracksToDKE__Ellipsoids_DDPlus model to predict the KDE, and then feed it into a SimpleCNN model to predict the target histograms.  Initially, it will use previously trained weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the current GPU usage. Please try to be nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WARNING**: The card numbers here are *not* the same as in CUDA. You have been warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Python 3 standard library\n",
    "from pathlib import Path\n",
    "\n",
    "from model.efficiency import pv_locations, efficiency\n",
    "\n",
    "##from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up local parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "\n",
    "# Name is the output file name\n",
    "\n",
    "\n",
    "##  200719  mds\n",
    "##folder = '20December_Tracks_to_KDE_TestTrainedModel'\n",
    "##folder = '22December_testing_DDplus_loss_Bb_iter2_floatAll_100epochs_3em6'\n",
    "folder = '10Jan2021_TracksToHists_B_next40epochs_lr_2em3__b32_2p5_kde2hists_floatFinalFilter'\n",
    "name = folder\n",
    "\n",
    "# Make an output folder named \"name\" (change if you want)\n",
    "\n",
    "## Special instructions for those working on goofy at UC\n",
    "## Please be very careful to make sure that your folder\n",
    "## does not live in a subdirectory of your home directory\n",
    "## this disk has very little capacity. Instead, use \n",
    "## a subdirectory in /share/lazy with a symbolic link to\n",
    "## it in this (the notebooks) subdirectory\n",
    "folder = 'ML/' + folder\n",
    "output = Path(folder)\n",
    "\n",
    "\n",
    "# Size of batches\n",
    "batch_size = 32\n",
    "# How fast to learn\n",
    "## learning rate was 1e-7 for all layers in TracksToHists_A\n",
    "## here we want to learn only weights in the finalFilter layer\n",
    "## of TracksToHists_B, so try a high learning rate, at least initially\n",
    "## 1e-3 did well for the first 10 epochs; let's increase it for the next 40\n",
    "learning_rate = 2e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the output directory if it does not exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the helper functions\n",
    "\n",
    "Add the directory with the model\n",
    "definitions to the path so we can import from it:\n",
    "\n",
    "> When you type `import X`,\n",
    "Python searches `sys.path` for a python\n",
    "file named `X.py` to import. So we need to add the model directory to the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# From model/collectdata.py\n",
    "##from model.collectdata_kde_Ellipsoids import collect_t2kde_data\n",
    "from model.collectdata_t2hists import collect_t2hists_data\n",
    "from model.collectdata_mdsA  import collect_truth\n",
    "\n",
    "# From model/loss.py\n",
    "##from loss import Loss\n",
    "##from model.kde_loss_D import Loss\n",
    "## from model.kde_loss_B import Loss  ## Tracks_to_KDE loss, not for target hists\n",
    "\n",
    "##  \"standard\" ratios loss for hists training\n",
    "from model.alt_loss_A import Loss  ## loss used to train RunModel_Demo_28November2020-SimpleCNNLayer_Ca-Restart_5\n",
    "\n",
    "\n",
    "##from model.models_kde import TracksToKDE_Ellipsoids_DirtyDozen as Model\n",
    "from model.models_kde import TracksToKDE_Ellipsoids_DDplus as t2kde_model\n",
    "##from model.models_mds_G import SimpleCNN5Layer_Ca as kde2hists_model\n",
    "from model.models_mds_28Dec20 import SimpleCNN5Layer_Ca as kde2hists_model  ## copy of models_mds_01June20 for debugging\n",
    "from model.models_t2hists import TracksToHists_B as t2hists_model\n",
    "\n",
    "\n",
    "##from model.training_kde import trainNet, select_gpu, Results\n",
    "## training_t2hists_A.py increases \"difference\" for accepting found\n",
    "## peaks as matched from 5 bins to 7.5 bins (compmared to original training.py)\n",
    "from model.training_t2hists_A import trainNet, select_gpu, Results\n",
    "from model.plots import dual_train_plots, replace_in_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets built up during the run - do not rerun this cell\n",
    "results = pd.DataFrame([], columns=Results._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Torch device configuration. All tensors and model parameters need to know where to be put.\n",
    "This takes a BUS ID number: The BUS ID is the same as the listing at the top of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_gpu(0)\n",
    "##device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Load the dataset, split into parts, then move to device (see `collectdata.py` in the `../model` directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 210109 let's use some of Will's toy MC for training rather than the 20K sample I've been using\n",
    "\n",
    "##train_loader = collect_t2hists_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "train_loader = collect_t2hists_data('/share/lazy/will/data/June30_2020_80k_1.h5',    \n",
    "                             batch_size=batch_size,\n",
    "## if we are using a larger dataset (240K events, with the datasets above, and 11 GB  of GPU memory),\n",
    "## not the dataset will overflow the GPU memory; device=device will allow the data to move back\n",
    "## and forth between the CPU and GPU memory. While this allows use of a larger dataset, it slows\n",
    "## down performance by about 10%.  So comment out when not needed.\n",
    "##                           device=device,\n",
    "##                             slice = slice(0,18000)\n",
    "                           )\n",
    "\n",
    "\n",
    "\n",
    "                            \n",
    "# Validation dataset. You can slice to reduce the size.\n",
    "## mds no separate validation set yet,\n",
    "\n",
    "## 210109 and use everything in this 20K file for validation\n",
    "val_loader = collect_t2hists_data('dataAA/20K_POCA_kernel_evts_200926.h5',\n",
    "                            batch_size=batch_size,\n",
    "                            device=device,\n",
    "##                           slice = slice(18000,None)\n",
    "                           )\n",
    "\n",
    "PV = collect_truth('dataAA/20K_POCA_kernel_evts_200926.h5', pvs=True)\n",
    "print('PV.n.shape =    ',  PV.n.shape)\n",
    "print('PV.n[0].shape = ', *PV.n[0].shape)\n",
    "print('PV.x[0] =       ', *PV.x[0])\n",
    "print('PV.y[0] =       ', *PV.y[0])\n",
    "print('PV.z[0] =       ', *PV.z[0])\n",
    "print('PV.n[0] =       ', *PV.n[0])\n",
    "print('PV.cat[0] =     ', *PV.cat[0])\n",
    "\n",
    "SV = collect_truth('dataAA/20K_POCA_kernel_evts_200926.h5', pvs=False)\n",
    "print('SV.n.shape =    ', SV.n.shape)\n",
    "print('SV.n[0].shape = ', *SV.n[0].shape)\n",
    "print('SV.x[0] =       ', *SV.x[0])\n",
    "print('SV.y[0] =       ', *SV.y[0])\n",
    "print('SV.z[0] =       ', *SV.z[0])\n",
    "print('SV.n[0] =       ', *SV.n[0])\n",
    "print('SV.cat[0] =     ', *SV.cat[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a model, use multiple GPUs if they are VISIBLE, and move the model to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nOut1 = 50\n",
    "nOut2 = 50\n",
    "nOut3 = 50\n",
    "nOut4 = 50\n",
    "nOut5 = 50\n",
    "nOut6 = 50\n",
    "nOut7 = 50\n",
    "nOut8 = 50\n",
    "nOut9 = 50\n",
    "nOut10 = 50\n",
    "nOut11 = 50\n",
    "latentChannels = 4\n",
    "model_t2kde = t2kde_model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11,latentChannels)\n",
    "model_kde2hists = kde2hists_model()\n",
    "model_t2hists = t2hists_model(nOut1,nOut2,nOut3,nOut4,nOut5,nOut6,nOut7,nOut8,nOut9,nOut10,nOut11,latentChannels)\n",
    "\n",
    "##summary(model, input_size=(4, 4000))\n",
    "##print(model.parameters)\n",
    "\n",
    "## add the following code to allow the user to freeze the some of the weights corresponding \n",
    "## to those taken from an earlier model trained with the original target histograms\n",
    "## presumably -- this leaves either the perturbative filter \"fixed\" and lets the \n",
    "## learning focus on the non-perturbative features, so get started faster, or vice versa\n",
    "\n",
    "## 210110 For Iter0, freeze all weights other than those asociated with\n",
    "## the finalFilter added in moving from TracksToHists_A to TracksToHists_B\n",
    "ct = 0\n",
    "for child in model_t2hists.children():\n",
    "  print('ct, child = ',ct, \"  \", child)\n",
    "  if (ct < 27) :\n",
    "    print(\"     About to set param.requires_grad=False for ct = \", ct, \"params\")\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False \n",
    "  ct += 1\n",
    "\n",
    "loss = Loss(epsilon=1e-5,coefficient=2.5)\n",
    "optimizer = torch.optim.Adam(model_t2hists.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move the model's weight matricies to the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## want to look at all three dictionaries to start:\n",
    "##  t2kde\n",
    "##  kde2hists\n",
    "##  t2hists\n",
    "## the plan is to (initially) copy weights from separate dictionaries into th t2hists dictionary\n",
    "\n",
    "##   ML -> /share/lazy/sokoloff/ML\n",
    "'''\n",
    "model_t2kde_dict = model_t2kde.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_t2kde_dict\")\n",
    "index = 0\n",
    "for k,v in model_t2kde_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "#\n",
    "model_kde2hists_dict = model_kde2hists.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_hists_2kde_dict\")\n",
    "index = 0\n",
    "for k,v in model_kde2hists_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "#\n",
    "model_t2hists_dict = model_t2hists.state_dict()\n",
    "## mds 190725 for debugging\n",
    "print(\"for model_hists_2kde_dict\")\n",
    "index = 0\n",
    "for k,v in model_t2hists_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "#\n",
    "\n",
    "##  build the \"updated_dict\" to become the t2hists_dictionary from the\n",
    "##  t2kde and kde2hist dictionaries\n",
    "update_dict = model_t2hists_dict\n",
    "##print(\"updated_dict = \",updated_dict)\n",
    "## when starting \"ab initio\", reduce biases as the bias gets summed for each track\n",
    "## contributing to the predicted KDE\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "updated_dict[\"layer1.bias\"] = 0.005*model_dict[\"layer1.bias\"]\n",
    "updated_dict[\"layer2.bias\"] = 0.005*model_dict[\"layer2.bias\"]\n",
    "updated_dict[\"layer3.bias\"] = 0.005*model_dict[\"layer3.bias\"]\n",
    "updated_dict[\"layer4.bias\"] = 0.005*model_dict[\"layer4.bias\"]\n",
    "updated_dict[\"layer5.bias\"] = 0.005*model_dict[\"layer5.bias\"]\n",
    "updated_dict[\"layer6.bias\"] = 0.005*model_dict[\"layer6.bias\"]\n",
    "updated_dict[\"layer7.bias\"] = 0.005*model_dict[\"layer7.bias\"]\n",
    "updated_dict[\"layer8.bias\"] = 0.005*model_dict[\"layer8.bias\"]\n",
    "updated_dict[\"layer9.bias\"] = 0.005*model_dict[\"layer9.bias\"]\n",
    "updated_dict[\"layer10.bias\"] = 0.005*model_dict[\"layer10.bias\"]\n",
    "updated_dict[\"layer11.bias\"] = 0.005*model_dict[\"layer11.bias\"]\n",
    "'''\n",
    "\n",
    "'''\n",
    "##model_t2hists.load_state_dict(updated_dict,strict=False)\n",
    "\n",
    "##model__t2hists_dict = model_t2hists.state_dict()\n",
    "\n",
    "## let's get the tracks-to-kde model here\n",
    "t2kde_folder = '25December__DDplus_loss_Ba_iter5_floatAll_800epochs_5em6'  ## really iter6, really Dec. 27\n",
    "t2kde_folder = '25December__DDplus_loss_Ba_iter7_floatAll_800epochs_4em6'\n",
    "t2kde_name = t2kde_folder\n",
    "suffix = 'final'\n",
    "t2kde_dict_name = 'ML/' + t2kde_folder + '/' + t2kde_name + '_'+ suffix + '.pyt'\n",
    "print('t2kde_dict_name = ',t2kde_dict_name)\n",
    "pretrained_t2kde_dict = torch.load(t2kde_dict_name)\n",
    "\n",
    "print(\" \\n\",\"  for t2kde_pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_t2kde_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    "    \n",
    "    \n",
    "## let's get the hists-to-kde model here   \n",
    "kde2hists_folder = '02June2020_CNN5Layer_Ca_another200epochs_K'\n",
    "kde2hists_name = kde2hists_folder\n",
    "suffix = 'final'\n",
    "kde2hists_dict_name = 'ML/' + kde2hists_folder + '/' + kde2hists_name + '_'+ suffix + '.pyt'\n",
    "## mds dec28 print('kde2hists_dict_name = ',kde2hists_dict_name)\n",
    "pretrained_kde2hists_dict = torch.load(kde2hists_dict_name)\n",
    "\n",
    "print(\" \\n\",\"  for kde2hists_pretrained_dict\")\n",
    "index = 0\n",
    "for k,v in pretrained_kde2hists_dict.items():\n",
    "    print(\"index, k =  \",index,\"  \",k)\n",
    "    index = index+1\n",
    " \n",
    "\n",
    "\n",
    "##print(\"model_dict instantiated\")\n",
    "# 1. filter out unnecessary keys\n",
    "pretrained_dict = {k: v for k, v in pretrained_t2kde_dict.items() if k in model_t2hists_dict}\n",
    "## mds dec28 print(\"pretrained_dict iterated\")\n",
    "# 2. overwrite entries in the existing state dict\n",
    "model_t2hists_dict.update(pretrained_dict) \n",
    "\n",
    "update_dict[\"hist_conv1.weight\"] = pretrained_kde2hists_dict[\"conv1.weight\"]\n",
    "update_dict[\"hist_conv1.bias\"]   = pretrained_kde2hists_dict[\"conv1.bias\"]\n",
    "update_dict[\"hist_conv2.weight\"] = pretrained_kde2hists_dict[\"conv2.weight\"]\n",
    "update_dict[\"hist_conv2.bias\"]   = pretrained_kde2hists_dict[\"conv2.bias\"]\n",
    "update_dict[\"hist_conv3.weight\"] = pretrained_kde2hists_dict[\"conv3.weight\"]\n",
    "update_dict[\"hist_conv3.bias\"]   = pretrained_kde2hists_dict[\"conv3.bias\"]\n",
    "update_dict[\"hist_conv4.weight\"] = pretrained_kde2hists_dict[\"conv4.weight\"]\n",
    "update_dict[\"hist_conv4.bias\"]   = pretrained_kde2hists_dict[\"conv4.bias\"]\n",
    "update_dict[\"hist_conv5.weight\"] = pretrained_kde2hists_dict[\"conv5.weight\"]\n",
    "update_dict[\"hist_conv5.bias\"]   = pretrained_kde2hists_dict[\"conv5.bias\"]\n",
    "update_dict[\"hist_fc1.weight\"]   = pretrained_kde2hists_dict[\"fc1.weight\"]\n",
    "update_dict[\"hist_fc1.bias\"]     = pretrained_kde2hists_dict[\"fc1.bias\"]\n",
    "\n",
    "##model_t2hists.update(update_dict,strict=False)\n",
    "model_t2hists.load_state_dict(update_dict,strict=False)\n",
    "model_t2hists_dict = model_t2hists.state_dict()\n",
    "'''\n",
    "\n",
    "##\n",
    "#   when starting from a model with a fully connected last layer rather than a convolutional layer\n",
    "# 3. load the new state dict\n",
    "#   need to use strict=False as the two models state model attributes do not agree exactly\n",
    "#   see https://pytorch.org/docs/master/_modules/torch/nn/modules/module.html#Module.load_state_dict\n",
    "\n",
    "t2hists_folder = '10Jan2021_TracksToHists_B_10epochs_lr_1em3_2p5_kde2hists_allFloat'\n",
    "t2hists_name = t2hists_folder\n",
    "suffix = 'final'\n",
    "t2hists_dict_name = 'ML/' + t2hists_folder + '/' +t2hists_name + '_'+ suffix + '.pyt'\n",
    "## mds dec28 print('kde2hists_dict_name = ',kde2hists_dict_name)\n",
    "pretrained_t2hists_dict = torch.load(t2hists_dict_name) \n",
    "\n",
    "model_t2hists.load_state_dict(pretrained_t2hists_dict,strict=False)\n",
    "\n",
    "##  print('model_t2hists_dict =    ', model_t2hists_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##print('validation.dataset.tensors = ',validation.dataset.tensors)\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_t2hists.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, tax, lax, lines = dual_train_plots()\n",
    "fig = ax.figure\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for result in trainNet(model, optimizer, loss,\n",
    "                        train_loader, val_loader,\n",
    "                        n_epochs, epoch_start=len(results),\n",
    "                        notebook=True):\n",
    "    \n",
    "    results = results.append(pd.Series(result._asdict()), ignore_index=True)\n",
    "    \n",
    "    xs = results.index\n",
    "##    print(\"xs = \",xs)\n",
    "    \n",
    "    # Update the plot above\n",
    "##    print(\"results.index = \",results.index,\"  results.cost\", results.cost)\n",
    "##    print(\"results.index = \",results.index,\"  results.val\", results.val)\n",
    "    lines['train'].set_data(results.index,results.cost)\n",
    "    lines['val'].set_data(results.index,results.val)\n",
    "    \n",
    "    #filter first cost epoch (can be really large)\n",
    "    max_cost = max(max(results.cost if len(results.cost)<2 else results.cost[1:]), max(results.val))\n",
    "    min_cost = min(min(results.cost), min(results.val))\n",
    "    \n",
    "    # The plot limits need updating too\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.set_ylim(min_cost*.9, max_cost*1.1)  \n",
    "    ax.set_xlim(-.5, len(results.cost) - .5)\n",
    "    \n",
    "    replace_in_ax(lax, lines['eff'], xs, results['eff_val'].apply(lambda x: x.eff_rate))\n",
    "    replace_in_ax(tax, lines['fp'], xs, results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "    \n",
    "    # Redraw the figure\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    # Save each model state dictionary\n",
    "    torch.save(model.state_dict(), output / f'{name}_{result.epoch}.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), output / f'{name}_final.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_hdf(f'{name}_stats.hdf5', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_train_plots(results.index,\n",
    "                 results.cost, results.val, \n",
    "                 results['eff_val'].apply(lambda x: x.eff_rate),\n",
    "                 results['eff_val'].apply(lambda x: x.fp_rate))\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(output / f'{name}_stats_a.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and save the final model (even though it was also saved above):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.cuda.empty_cache()\"\n",
    "##quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "june2020-gpu",
   "language": "python",
   "name": "june2020-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
